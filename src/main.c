#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <ctype.h>
#include <time.h>
#include <math.h>
#include <unistd.h>
#include "rich_config.h"
#include "adaptive_optimizer.h"
#include "data/dataset.h"
#include "data/split.h"
#include "data/data_loader.h"
#include "data/dataset_analyzer.h"
#include "neural/network.h"
#include "neural/network_simple.h"
#include "optimizers/optimizer.h"
#include "training/standard.h"
#include "training/adaptive.h"
#include "training/advanced.h"
#include "training/bayesian.h"
#include "training/progressive.h"
#include "training/swarm.h"
#include "training/propagation.h"
#include "reporting/experiment_results.h"
#include "args_parser.h"
#include "neural/layer.h"
#include "training/trainer.h"
#include "evaluation/metrics.h"
#include "evaluation/confusion_matrix.h"
#include "evaluation/f1_score.h"
#include "evaluation/roc.h"
#include "progress_bar.h"
#include "colored_output.h"
#include "model_saver/model_saver.h"

// Macro pour les messages de debug conditionnels
#define DEBUG_PRINTF(config, ...) do { \
    if ((config) && (config)->debug_mode) { \
        printf(__VA_ARGS__); \
    } \
} while(0)

// Variables globales pour acc√©der aux arguments de ligne de commande
static int argc_global = 0;
static char **argv_global = NULL;

// üéØ INTERFACE SIMPLIFI√âE POUR MODEL_SAVER
// ========================================

// Variable globale pour le ModelSaver
static ModelSaver *global_model_saver = NULL;

// Initialiser le syst√®me de sauvegarde des 10 meilleurs mod√®les avec nom de dataset
int init_best_models_manager_with_dataset(const char *base_directory, const char *dataset_name) {
    if (global_model_saver) {
        return 0; // D√©j√† initialis√©
    }
    
    // Cr√©er le r√©pertoire sp√©cifique au dataset
    char save_directory[512];
    if (dataset_name && strlen(dataset_name) > 0) {
        snprintf(save_directory, sizeof(save_directory), "%s_%s", base_directory, dataset_name);
    } else {
        snprintf(save_directory, sizeof(save_directory), "%s_default", base_directory);
    }
    
    global_model_saver = model_saver_create(save_directory);
    if (!global_model_saver) {
        printf("‚ùå Erreur: Impossible d'initialiser ModelSaver\n");
        return -1;
    }
    
    printf("‚úÖ Gestionnaire des 10 meilleurs mod√®les initialis√© pour dataset '%s': %s\n", 
           dataset_name ? dataset_name : "default", save_directory);
    return 0;
}

// Initialiser le syst√®me de sauvegarde des 10 meilleurs mod√®les (version legacy)
int init_best_models_manager(const char *save_directory) {
    return init_best_models_manager_with_dataset(save_directory, NULL);
}

// Ajouter un mod√®le candidat aux 10 meilleurs
int add_candidate_model(const char *model_name, const char *optimizer, const char *method, 
                       const char *activation, float accuracy, float loss, 
                       float val_accuracy, float val_loss, float f1_score, 
                       float learning_rate, int epoch) {
    if (!global_model_saver) {
        return -1;
    }
    
    // Cr√©er un trainer fictif pour l'interface model_saver
    Trainer trainer = {0};
    trainer.learning_rate = learning_rate;
    trainer.batch_size = 32;
    trainer.epochs = epoch;
    strncpy(trainer.optimizer_name, optimizer, sizeof(trainer.optimizer_name) - 1);
    strncpy(trainer.strategy_name, method, sizeof(trainer.strategy_name) - 1);
    
    // Ajouter le mod√®le candidat (sans le r√©seau pour √©viter les probl√®mes m√©moire)
    // On utilise NULL pour le r√©seau car on ne sauvegarde que les m√©tadonn√©es
    return model_saver_add_candidate(global_model_saver, NULL, &trainer,
                                   accuracy, loss, val_accuracy, val_loss, epoch);
}

// Finaliser la sauvegarde des meilleurs mod√®les
int finalize_best_models() {
    if (!global_model_saver) {
        printf("‚ö†Ô∏è Gestionnaire des meilleurs mod√®les non initialis√©\n");
        return 0;
    }
    
    printf("\nüíæ === FINALISATION DE LA SAUVEGARDE DES MEILLEURS MOD√àLES ===\n");
    
    // Afficher le classement final
    model_saver_print_rankings(global_model_saver);
    
    // Exporter l'interface Python
    char python_file[512];
    snprintf(python_file, sizeof(python_file), "%s/model_loader.py", 
             global_model_saver->save_directory);
    
    if (model_saver_export_python_interface(global_model_saver, python_file) == 0) {
        printf("üêç Interface Python export√©e: %s\n", python_file);
    }
    
    printf("\n‚úÖ Sauvegarde termin√©e:\n");
    printf("   üìä %d mod√®les dans le top 10\n", global_model_saver->count);
    printf("   üìÅ Dossier: %s/\n", global_model_saver->save_directory);
    printf("   üêç Script d'analyse: %s\n", python_file);
    
    return global_model_saver->count;
}

// Nettoyer le gestionnaire des meilleurs mod√®les
void cleanup_best_models() {
    if (global_model_saver) {
        model_saver_free(global_model_saver);
        global_model_saver = NULL;
    }
}

// FIN DE L'INTERFACE SIMPLIFI√âE POUR MODEL_SAVER
// ==============================================

// Prototype du parser YAML riche (doit √™tre compil√© avec yaml_parser_rich.c)
int parse_yaml_rich_config(const char *filename, RichConfig *cfg);

// Structure pour stocker toutes les m√©triques
typedef struct {
    float accuracy;
    float precision;
    float recall;
    float f1_score;
    float auc_roc;
} AllMetrics;

// Syst√®me de cache pour les architectures (nouveau)
typedef struct {
    int optimizer_index;
    int activation_index;
    size_t layer_sizes[5];
    const char *activations[4];
    int num_layers;
    int arch_variant;
} ArchitectureCache;

// Cache global pour √©viter de recalculer les architectures
static ArchitectureCache arch_cache[64]; // Support pour 64 combinaisons max
static int cache_initialized = 0;

// Fonction pour initialiser le cache d'architectures
void initialize_architecture_cache(int num_optimizers, int num_activations, const char **activation_names) {
    if (cache_initialized) return;
    
    int cache_index = 0;
    for (int o = 0; o < num_optimizers && cache_index < 64; o++) {
        for (int a = 0; a < num_activations && cache_index < 64; a++) {
            arch_cache[cache_index].optimizer_index = o;
            arch_cache[cache_index].activation_index = a;
            arch_cache[cache_index].arch_variant = (o * num_activations + a) % 6;
            
            // Pr√©-calculer l'architecture
            switch(arch_cache[cache_index].arch_variant) {
                case 0: // Architecture minimaliste
                    arch_cache[cache_index].layer_sizes[0] = 8;  // 8 features m√©dicales
                    arch_cache[cache_index].layer_sizes[1] = 64;
                    arch_cache[cache_index].layer_sizes[2] = 1; // Classification binaire
                    arch_cache[cache_index].activations[0] = activation_names[a];
                    arch_cache[cache_index].activations[1] = "sigmoid";
                    arch_cache[cache_index].num_layers = 3;
                    break;
                    
                case 1: // Architecture √©quilibr√©e
                    arch_cache[cache_index].layer_sizes[0] = 8;
                    arch_cache[cache_index].layer_sizes[1] = 128;
                    arch_cache[cache_index].layer_sizes[2] = 64;
                    arch_cache[cache_index].layer_sizes[3] = 1;
                    arch_cache[cache_index].activations[0] = activation_names[a];
                    arch_cache[cache_index].activations[1] = activation_names[a];
                    arch_cache[cache_index].activations[2] = "sigmoid";
                    arch_cache[cache_index].num_layers = 4;
                    break;
                    
                case 2: // Architecture large
                    arch_cache[cache_index].layer_sizes[0] = 8;
                    arch_cache[cache_index].layer_sizes[1] = 256;
                    arch_cache[cache_index].layer_sizes[2] = 128;
                    arch_cache[cache_index].layer_sizes[3] = 1;
                    arch_cache[cache_index].activations[0] = activation_names[a];
                    arch_cache[cache_index].activations[1] = activation_names[a];
                    arch_cache[cache_index].activations[2] = "sigmoid";
                    arch_cache[cache_index].num_layers = 4;
                    break;
                    
                case 3: // Architecture profonde
                    arch_cache[cache_index].layer_sizes[0] = 8;
                    arch_cache[cache_index].layer_sizes[1] = 128;
                    arch_cache[cache_index].layer_sizes[2] = 64;
                    arch_cache[cache_index].layer_sizes[3] = 32;
                    arch_cache[cache_index].layer_sizes[4] = 1;
                    arch_cache[cache_index].activations[0] = activation_names[a];
                    arch_cache[cache_index].activations[1] = activation_names[a];
                    arch_cache[cache_index].activations[2] = activation_names[a];
                    arch_cache[cache_index].activations[3] = "sigmoid";
                    arch_cache[cache_index].num_layers = 5;
                    break;
                    
                case 4: // Architecture √©troite
                    arch_cache[cache_index].layer_sizes[0] = 8;
                    arch_cache[cache_index].layer_sizes[1] = 32;
                    arch_cache[cache_index].layer_sizes[2] = 16;
                    arch_cache[cache_index].layer_sizes[3] = 1;
                    arch_cache[cache_index].activations[0] = activation_names[a];
                    arch_cache[cache_index].activations[1] = activation_names[a];
                    arch_cache[cache_index].activations[2] = "sigmoid";
                    arch_cache[cache_index].num_layers = 4;
                    break;
                    
                default: // Architecture tr√®s large (cas 5)
                    arch_cache[cache_index].layer_sizes[0] = 8;
                    arch_cache[cache_index].layer_sizes[1] = 512;
                    arch_cache[cache_index].layer_sizes[2] = 256;
                    arch_cache[cache_index].layer_sizes[3] = 1;
                    arch_cache[cache_index].activations[0] = activation_names[a];
                    arch_cache[cache_index].activations[1] = activation_names[a];
                    arch_cache[cache_index].activations[2] = "sigmoid";
                    arch_cache[cache_index].num_layers = 4;
                    break;
            }
            cache_index++;
        }
    }
    cache_initialized = 1;
}

// Fonction pour obtenir une architecture depuis le cache
ArchitectureCache* get_cached_architecture(int optimizer_idx, int activation_idx) {
    for (int i = 0; i < 64; i++) {
        if (arch_cache[i].optimizer_index == optimizer_idx && 
            arch_cache[i].activation_index == activation_idx) {
            return &arch_cache[i];
        }
    }
    return NULL;
}

// Fonction pour calculer toutes les m√©triques (CORRIG√âE pour de meilleures performances)
AllMetrics compute_all_metrics(NeuralNetwork *network, Dataset *dataset, const RichConfig *config) {
    AllMetrics metrics = {0};
    
    if (!network || !dataset || dataset->num_samples == 0) {
        return metrics;
    }
    
    // D√©sactiver dropout pour √©valuation
    network_set_dropout_simple(network, 0);
    
    // Pr√©parer les tableaux pour les pr√©dictions
    float *y_true = malloc(dataset->num_samples * sizeof(float));
    float *y_pred = malloc(dataset->num_samples * sizeof(float));
    float *y_scores = malloc(dataset->num_samples * sizeof(float)); // Pour AUC-ROC
    int *y_true_int = malloc(dataset->num_samples * sizeof(int));
    int *y_pred_int = malloc(dataset->num_samples * sizeof(int));
    
    if (!y_true || !y_pred || !y_scores || !y_true_int || !y_pred_int) {
        printf("Erreur: allocation m√©moire pour les m√©triques\n");
        free(y_true); free(y_pred); free(y_scores); free(y_true_int); free(y_pred_int);
        return metrics;
    }
    
    // üîß CORRECTION CRITIQUE: Analyser les pr√©dictions pour debug
    int predictions_0 = 0, predictions_1 = 0;
    int targets_0 = 0, targets_1 = 0;
    float min_score = 1.0f, max_score = 0.0f;
    float sum_scores = 0.0f;
    int valid_predictions = 0;
    
    // üö® CORRECTION CRITIQUE: Faire les pr√©dictions correctement
    for (size_t i = 0; i < dataset->num_samples; i++) {
        network_forward_simple(network, dataset->inputs[i]);
        
        float *output = network_output_simple(network);
        if (!output) continue;
        
        float prediction_score = output[0]; // Score brut (probabilit√©)
        float target = dataset->outputs[i][0];
        
        // üîß CORRECTION: V√©rifier que les scores sont valides
        if (isnan(prediction_score) || isinf(prediction_score)) {
            prediction_score = 0.5f; // Score par d√©faut
        }
        
        // üîß CORRECTION: Analyser la distribution des scores
        if (prediction_score < min_score) min_score = prediction_score;
        if (prediction_score > max_score) max_score = prediction_score;
        sum_scores += prediction_score;
        valid_predictions++;
        
        y_true[i] = target;
        y_scores[i] = prediction_score;
        y_true_int[i] = (int)(target > 0.5f ? 1 : 0);
        
        // Compter les distributions des targets
        if (target > 0.5f) targets_1++; else targets_0++;
    }
    
    // üîß CORRECTION MAJEURE: Calcul du seuil optimal dynamique
    float optimal_threshold = 0.5f; // Seuil par d√©faut
    
    if (valid_predictions > 0) {
        float mean_score = sum_scores / valid_predictions;
        float score_range = max_score - min_score;
        
        // üîß PROBL√àME D√âTECT√â: Si toutes les pr√©dictions sont identiques ou dans une plage tr√®s √©troite
        // Maintenant conditionnel au debug_mode et avec seuil plus tol√©rant
        if (score_range < 0.001f) {  // Plus strict : seulement si vraiment identiques
            DEBUG_PRINTF(config, "‚ö†Ô∏è PROBL√àME: R√©seau pr√©dit dans une plage tr√®s √©troite!\n");
            DEBUG_PRINTF(config, "   Scores min/max: %.6f/%.6f (plage: %.6f)\n", min_score, max_score, score_range);
            
            // Utiliser la moyenne comme seuil si la plage est trop √©troite
            if (mean_score > 0.0f && mean_score < 1.0f) {
                optimal_threshold = mean_score;
                DEBUG_PRINTF(config, "   üîß Ajustement: Utilisation de la moyenne (%.6f) comme seuil\n", optimal_threshold);
            } else {
                // Utiliser un seuil bas√© sur la distribution des targets
                optimal_threshold = (float)targets_1 / (targets_0 + targets_1);
                DEBUG_PRINTF(config, "   üîß Ajustement: Utilisation du ratio des classes (%.6f) comme seuil\n", optimal_threshold);
            }
        } else if (score_range < 0.01f) {
            // Avertissement plus doux pour plages √©troites mais pas critiques
            DEBUG_PRINTF(config, "‚ÑπÔ∏è Plage de pr√©diction √©troite: %.6f (peut indiquer un d√©but de saturation)\n", score_range);
            optimal_threshold = (min_score + max_score) / 2.0f;
        } else {
            // Seuil optimal bas√© sur la distribution si la plage est suffisante
            optimal_threshold = (min_score + max_score) / 2.0f;
        }
    }
    
    // Appliquer le seuil optimal pour les pr√©dictions
    for (size_t i = 0; i < dataset->num_samples; i++) {
        float prediction_class = (y_scores[i] > optimal_threshold) ? 1.0f : 0.0f;
        y_pred[i] = prediction_class;
        y_pred_int[i] = (int)(prediction_class > 0.5f ? 1 : 0);
        
        // Compter les distributions des pr√©dictions
        if (prediction_class > 0.5f) predictions_1++; else predictions_0++;
    }
    
    // üîß DEBUG: Afficher les statistiques de pr√©diction
    DEBUG_PRINTF(config, "üîç Debug M√©triques: Scores [%.4f, %.4f] | Pred[0:%d, 1:%d] | True[0:%d, 1:%d] | Seuil: %.4f\n", 
           min_score, max_score, predictions_0, predictions_1, targets_0, targets_1, optimal_threshold);
    
    // 1. Accuracy - utiliser les valeurs float pour plus de pr√©cision
    metrics.accuracy = accuracy(y_true, y_pred, dataset->num_samples);
    
    // 2. Confusion Matrix pour Precision, Recall, F1
    int TP, TN, FP, FN;
    compute_confusion_matrix(y_true_int, y_pred_int, dataset->num_samples, &TP, &TN, &FP, &FN);
    
    // üîß DEBUG: Afficher la matrice de confusion
    DEBUG_PRINTF(config, "   Matrice: TP=%d FP=%d FN=%d TN=%d\n", TP, FP, FN, TN);
    
    // üîß CORRECTION 2: V√©rifications de s√©curit√© pour √©viter division par z√©ro
    // 3. Precision, Recall, F1-Score avec gestion des cas limites
    if (TP + FP > 0) {
        metrics.precision = (float)TP / (TP + FP);
    } else {
        metrics.precision = (predictions_1 == 0) ? 1.0f : 0.0f; // 1.0 si aucune pr√©diction positive et c'est correct
        if (predictions_1 == 0) {
            DEBUG_PRINTF(config, "   ‚ÑπÔ∏è Precision=1: Aucune pr√©diction positive (correct si aucun vrai positif)\n");
        } else {
            DEBUG_PRINTF(config, "   ‚ö†Ô∏è Precision=0: Aucune pr√©diction positive (TP+FP=0)\n");
        }
    }
    
    if (TP + FN > 0) {
        metrics.recall = (float)TP / (TP + FN);
    } else {
        metrics.recall = (targets_1 == 0) ? 1.0f : 0.0f; // 1.0 si aucun vrai positif dans les donn√©es
        if (targets_1 == 0) {
            DEBUG_PRINTF(config, "   ‚ÑπÔ∏è Recall=1: Aucun vrai positif dans les donn√©es (correct)\n");
        } else {
            DEBUG_PRINTF(config, "   ‚ö†Ô∏è Recall=0: √âchec de d√©tection des vrais positifs\n");
        }
    }
    
    // F1-Score avec v√©rification am√©lior√©e
    if (metrics.precision + metrics.recall > 0) {
        metrics.f1_score = 2.0f * metrics.precision * metrics.recall / (metrics.precision + metrics.recall);
    } else {
        // Cas sp√©cial : si pas de positifs dans les donn√©es ET pas de pr√©dictions positives
        if (targets_1 == 0 && predictions_1 == 0) {
            metrics.f1_score = 1.0f; // Parfait pour ce cas
            DEBUG_PRINTF(config, "   ‚ÑπÔ∏è F1=1: Pas de positifs dans les donn√©es et pas de fausses pr√©dictions positives\n");
        } else {
            metrics.f1_score = 0.0f;
        }
    }
    
    // üîß CORRECTION 3: V√©rification alternative pour F1-Score
    // Utiliser aussi la fonction d√©di√©e pour double v√©rification
    float f1_check = compute_f1_score(TP, FP, FN);
    if (fabs(metrics.f1_score - f1_check) > 0.001f) {
        // En cas de diff√©rence, utiliser la fonction d√©di√©e
        metrics.f1_score = f1_check;
    }
    
    // 4. AUC-ROC avec v√©rification de validit√© (maintenant robuste)
    metrics.auc_roc = compute_auc(y_true, y_scores, dataset->num_samples);
    
    // üîß CORRECTION 4: Validation des m√©triques calcul√©es
    // S'assurer que toutes les m√©triques sont dans des plages valides
    if (metrics.accuracy < 0.0f || metrics.accuracy > 1.0f) metrics.accuracy = 0.0f;
    if (metrics.precision < 0.0f || metrics.precision > 1.0f) metrics.precision = 0.0f;
    if (metrics.recall < 0.0f || metrics.recall > 1.0f) metrics.recall = 0.0f;
    if (metrics.f1_score < 0.0f || metrics.f1_score > 1.0f) metrics.f1_score = 0.0f;
    if (metrics.auc_roc < 0.0f || metrics.auc_roc > 1.0f) metrics.auc_roc = 0.5f; // AUC par d√©faut
    
    // üîß CORRECTION 5: Debug final pour v√©rifier les r√©sultats
    printf("   üìä R√©sultats: Acc=%.3f Prec=%.3f Rec=%.3f F1=%.3f AUC=%.3f\n", 
           metrics.accuracy, metrics.precision, metrics.recall, metrics.f1_score, metrics.auc_roc);
    
    // üîß CORRECTION 6: Validation sp√©ciale pour datasets d'images
    // Les datasets d'images peuvent avoir des caract√©ristiques diff√©rentes
    if (dataset->input_cols > 100) { // Probablement un dataset d'images (ex: 64 pixels = 8x8x1)
        printf("   üñºÔ∏è Dataset d'images d√©tect√© (%zu features) - m√©triques adapt√©es\n", dataset->input_cols);
        
        // Pour les images, on peut √™tre plus tol√©rant sur les seuils
        if (metrics.accuracy > 0.6f && metrics.f1_score < 0.1f) {
            printf("   ‚ö†Ô∏è Possible d√©s√©quilibre de classes dans le dataset d'images\n");
        }
    }
    
    // R√©activer dropout pour entra√Ænement
    network_set_dropout_simple(network, 1);
    
    // Nettoyage
    free(y_true);
    free(y_pred);
    free(y_scores);
    free(y_true_int);
    free(y_pred_int);
    
    return metrics;
}

// Fonctions utilitaires pour le banner adaptatif (copi√©es de progress_bar.c)
static int calculate_visible_length_banner(const char* str) {
    int visible_length = 0;
    int in_escape = 0;
    
    for (int i = 0; str[i] != '\0'; i++) {
        if (str[i] == '\033') {
            in_escape = 1;
        } else if (in_escape && str[i] == 'm') {
            in_escape = 0;
        } else if (!in_escape) {
            // Compter les caract√®res Unicode comme 1 caract√®re visuel
            if ((unsigned char)str[i] >= 0x80) {
                // Caract√®re Unicode multi-byte, on compte comme 1
                visible_length++;
                // Ignorer les bytes suivants de ce caract√®re Unicode
                while (i + 1 < strlen(str) && (unsigned char)str[i + 1] >= 0x80 && (unsigned char)str[i + 1] < 0xC0) {
                    i++;
                }
            } else {
                visible_length++;
            }
        }
    }
    
    return visible_length;
}

static void print_adaptive_border_line_banner(const char* corner_left, const char* fill, const char* corner_right, int content_width) {
    int total_width = content_width + 4; // 2 espaces + 2 bordures
    if (total_width < 40) total_width = 40; // Largeur minimale
    if (total_width > 80) total_width = 80; // Largeur maximale
    
    printf("%s", corner_left);
    for (int i = 0; i < total_width - 2; i++) {
        printf("%s", fill);
    }
    printf("%s\n", corner_right);
}

static void print_adaptive_content_line_banner(const char* content, const char* color, int content_width) {
    int total_width = content_width + 4; // 2 espaces + 2 bordures
    if (total_width < 40) total_width = 40; // Largeur minimale
    if (total_width > 80) total_width = 80; // Largeur maximale
    
    int visible_length = calculate_visible_length_banner(content);
    int padding = total_width - 4 - visible_length; // Espace restant apr√®s le contenu
    int left_padding = padding / 2;
    int right_padding = padding - left_padding;
    
    printf("%s‚ïë\033[0m", color);
    
    // Espacement √† gauche
    for (int i = 0; i < left_padding + 1; i++) {
        printf(" ");
    }
    
    // Contenu
    printf("%s", content);
    
    // Espacement √† droite
    for (int i = 0; i < right_padding + 1; i++) {
        printf(" ");
    }
    
    printf("%s‚ïë\033[0m\n", color);
}

// Banner ASCII Art styl√© avec largeur adaptative
void print_banner() {
    printf("\033[2J\033[H"); // Effacer l'√©cran et positionner le curseur en haut
    printf("\n");
    
    // Calculer la largeur n√©cessaire pour chaque ligne du banner
    char ascii_lines[][256] = {
        "",
        "_   _                      ____  _           _   ",
        "| \\ | | ___ _   _ _ __ ___  |  _ \\| | __ _ ___| |_ ",
        "|  \\| |/ _ \\ | | | '__/ _ \\ | |_) | |/ _` / __| __|",
        "| |\\  |  __/ |_| | | | (_) |  __/| | (_| \\__ \\ |_ ",
        "|_| \\_|\\___|\\__,_|_|  \\___/|_|   |_|\\__,_|___/\\__|",
        "",
        "üß† NEUROPLAST - Framework IA Modulaire en C üß†",
        "(c) Fabrice | v4.0 | Open Source - 2024-2025",
        "",
        "D√©di√© √† la recherche IA et neurosciences en C natif",
        "‚ö° Optimisation temps r√©el ‚Ä¢ 95%% accuracy automatique ‚ö°"
    };
    
    int num_lines = sizeof(ascii_lines) / sizeof(ascii_lines[0]);
    int max_width = 0;
    
    // Trouver la largeur maximale
    for (int i = 0; i < num_lines; i++) {
        int width = calculate_visible_length_banner(ascii_lines[i]);
        if (width > max_width) max_width = width;
    }
    
    // Afficher le banner avec largeur adaptative
    printf("\033[96m");
    print_adaptive_border_line_banner("‚ïî", "‚ïê", "‚ïó", max_width);
    printf("\033[0m");
    
    printf("\033[96m");
    print_adaptive_content_line_banner("", "\033[96m", max_width);
    printf("\033[0m");
    
    // Lignes ASCII art
    for (int i = 1; i <= 5; i++) {
        char colored_line[512];
        snprintf(colored_line, sizeof(colored_line), "\033[93m%s\033[0m", ascii_lines[i]);
        printf("\033[96m");
        print_adaptive_content_line_banner(colored_line, "\033[96m", max_width);
        printf("\033[0m");
    }
    
    printf("\033[96m");
    print_adaptive_content_line_banner("", "\033[96m", max_width);
    printf("\033[0m");
    
    printf("\033[96m");
    print_adaptive_border_line_banner("‚ï†", "‚ïê", "‚ï£", max_width);
    printf("\033[0m");
    
    char title_line[256];
    snprintf(title_line, sizeof(title_line), "\033[92m%s\033[0m", ascii_lines[7]);
    printf("\033[96m");
    print_adaptive_content_line_banner(title_line, "\033[96m", max_width);
    printf("\033[0m");
    
    char version_line[256];
    snprintf(version_line, sizeof(version_line), "\033[94m%s\033[0m", ascii_lines[8]);
    printf("\033[96m");
    print_adaptive_content_line_banner(version_line, "\033[96m", max_width);
    printf("\033[0m");
    
    printf("\033[96m");
    print_adaptive_border_line_banner("‚ï†", "‚ïê", "‚ï£", max_width);
    printf("\033[0m");
    
    char desc_line[256];
    snprintf(desc_line, sizeof(desc_line), "\033[95m%s\033[0m", ascii_lines[10]);
    printf("\033[96m");
    print_adaptive_content_line_banner(desc_line, "\033[96m", max_width);
    printf("\033[0m");
    
    char perf_line[256];
    snprintf(perf_line, sizeof(perf_line), "\033[91m%s\033[0m", ascii_lines[11]);
    printf("\033[96m");
    print_adaptive_content_line_banner(perf_line, "\033[96m", max_width);
    printf("\033[0m");
    
    printf("\033[96m");
    print_adaptive_border_line_banner("‚ïö", "‚ïê", "‚ïù", max_width);
    printf("\033[0m");
    printf("\n");
}

// Affichage d√©taill√© de la config lue
void print_rich_config(const RichConfig *cfg) {
    printf("Dataset      : %s\n", cfg->dataset);
    printf("Batch size   : %d\n", cfg->batch_size);
    printf("Max epochs   : %d\n", cfg->max_epochs);
    printf("Learning rate: %f\n", cfg->learning_rate);
    printf("Early stopping: %s\n", cfg->early_stopping ? "‚úÖ Activ√©" : "‚ùå D√©sactiv√©");
    printf("Patience     : %d √©poques\n", cfg->patience);
    printf("Debug mode   : %s\n", cfg->debug_mode ? "üîç Activ√©" : "üîá Masqu√©");
    printf("Optimized parameters: %s\n", cfg->optimized_parameters ? "üöÄ Optimiseur temps r√©el" : "üìä Configuration statique");

    printf("\nNeuroplast methods (%d):\n", cfg->num_neuroplast_methods);
    for (int i = 0; i < cfg->num_neuroplast_methods; ++i) {
        printf("  - %s\n", cfg->neuroplast_methods[i].name);
    }

    printf("\nActivations (%d):\n", cfg->num_activations);
    for (int i = 0; i < cfg->num_activations; ++i) {
        const Activation *a = &cfg->activations[i];
        printf("  - %s", a->name);
        if (strlen(a->optimization_method)) printf(" (optimization: %s)", a->optimization_method);
        if (strlen(a->optimized_with)) printf(" (optimized_with: %s)", a->optimized_with);
        if (a->num_params > 0) {
            printf(" {");
            for (int j = 0; j < a->num_params; ++j) {
                printf("%s=%.4f", a->params[j].key, a->params[j].value);
                if (j < a->num_params - 1) printf(", ");
            }
            printf("}");
        }
        printf("\n");
    }

    printf("\nOptimizers (%d):\n", cfg->num_optimizers);
    for (int i = 0; i < cfg->num_optimizers; ++i) {
        const OptimizerDef *o = &cfg->optimizers[i];
        printf("  - %s", o->name);
        if (o->num_params > 0) {
            printf(" {");
            for (int j = 0; j < o->num_params; ++j) {
                printf("%s=%.4f", o->params[j].key, o->params[j].value);
                if (j < o->num_params - 1) printf(", ");
            }
            printf("}");
        }
        printf("\n");
    }

    printf("\nMetrics (%d):\n", cfg->num_metrics);
    for (int i = 0; i < cfg->num_metrics; ++i) {
        printf("  - %s\n", cfg->metrics[i].name);
    }
}

// Mapping string vers fonction d'entra√Ænement
TrainingStrategyFn get_train_strategy(const char *name) {
    if (strcmp(name, "standard") == 0) return train_standard;
    if (strcmp(name, "adaptive") == 0) return train_adaptive;
    if (strcmp(name, "advanced") == 0) return train_advanced;
    if (strcmp(name, "bayesian") == 0) return train_bayesian;
    if (strcmp(name, "progressive") == 0) return train_progressive;
    if (strcmp(name, "swarm") == 0) return train_swarm;
    if (strcmp(name, "propagation") == 0) return train_propagation;
    return train_standard;
}

// Conversion Activation YAML -> tableau de strings (pour le r√©seau)
void extract_activations(const RichConfig *cfg, int a_idx, int n_layers, char act_names[][64]) {
    // Pr√©parer les activations pour chaque couche
    for (int l = 0; l < n_layers; ++l) {
        // Copier le nom et le convertir en minuscules pour compatibilit√© avec get_activation_type
        const char *src = cfg->activations[a_idx].name;
        char *dst = act_names[l];
        while (*src) {
            *dst++ = tolower(*src++);
        }
        *dst = '\0';
    }
    
    // Derni√®re couche avec sigmoid pour classification binaire
    if (n_layers > 0) {
        strcpy(act_names[n_layers - 1], "sigmoid");
    }
}

// Mode de test inclus - utilise l'enum d√©finie dans args_parser.h

// Fonction pour identifier le mode de test
RunMode get_run_mode(int argc, char *argv[]) {
    for (int i = 1; i < argc; i++) {
        if (strcmp(argv[i], "--test-heart-disease") == 0) {
            return MODE_TEST_HEART_DISEASE;
        } else if (strcmp(argv[i], "--test-enhanced") == 0) {
            return MODE_TEST_ENHANCED;
        } else if (strcmp(argv[i], "--test-robust") == 0) {
            return MODE_TEST_ROBUST;
        } else if (strcmp(argv[i], "--test-optimized-metrics") == 0) {
            return MODE_TEST_OPTIMIZED_METRICS;
        } else if (strcmp(argv[i], "--test-all-activations") == 0) {
            return MODE_TEST_ALL_ACTIVATIONS;
        } else if (strcmp(argv[i], "--test-all-optimizers") == 0) {
            return MODE_TEST_ALL_OPTIMIZERS;
        } else if (strcmp(argv[i], "--test-neuroplast-methods") == 0) {
            return MODE_TEST_NEUROPLAST_METHODS;
        } else if (strcmp(argv[i], "--test-complete-combinations") == 0) {
            return MODE_TEST_COMPLETE_COMBINATIONS;
        } else if (strcmp(argv[i], "--test-benchmark-full") == 0) {
            return MODE_TEST_BENCHMARK_FULL;
        } else if (strcmp(argv[i], "--test-all") == 0) {
            return MODE_TEST_ALL;
        }
    }
    return MODE_DEFAULT;
}

// Impl√©mentation du test de toutes les activations
int test_all_activations() {
    printf("üéØ TEST COMPLET DE TOUTES LES ACTIVATIONS\n");
    printf("=========================================\n\n");
    
    const char *activations[] = {
        "neuroplast", "relu", "leaky_relu", "gelu", 
        "sigmoid", "tanh", "elu", "mish", "swish", "prelu"
    };
    int num_activations = sizeof(activations) / sizeof(activations[0]);
    
    // Cr√©er un dataset XOR simple pour test rapide
    size_t layer_sizes[] = {2, 256, 128, 1};
    
    printf("üèóÔ∏è Architecture de test : Input(2)‚Üí256‚Üí128‚ÜíOutput(1)\n");
    printf("üìä Dataset : XOR (4 √©chantillons)\n");
    printf("‚ö° Optimiseur : AdamW (learning_rate=0.001)\n");
    printf("üéØ Objectif : Convergence √† 95%% d'accuracy\n\n");
    
    for (int i = 0; i < num_activations; i++) {
        printf("üß™ Test activation %d/%d : %s\n", i+1, num_activations, activations[i]);
        
        const char *test_activations[] = {activations[i], activations[i], "sigmoid"};
        NeuralNetwork *network = network_create_simple(4, layer_sizes, test_activations);
        
        if (!network) {
            printf("‚ùå Erreur cr√©ation r√©seau pour %s\n", activations[i]);
            continue;
        }
        
        // Test XOR rapide (100 √©poques max)
        float best_accuracy = 0.0f;
        int converged = 0;
        
        for (int epoch = 0; epoch < 100 && !converged; epoch++) {
            // XOR training data
            float inputs[4][2] = {{0,0}, {0,1}, {1,0}, {1,1}};
            float targets[4] = {0, 1, 1, 0};
            
            for (int sample = 0; sample < 4; sample++) {
                network_forward_simple(network, inputs[sample]);
                float target_array[] = {targets[sample]};
                network_backward_simple(network, inputs[sample], target_array, 0.001f);
            }
            
            // Test accuracy toutes les 10 √©poques
            if (epoch % 10 == 0) {
                int correct = 0;
                for (int sample = 0; sample < 4; sample++) {
                    network_forward_simple(network, inputs[sample]);
                    float *output = network_output_simple(network);
                    float prediction = output[0] > 0.5f ? 1.0f : 0.0f;
                    if (fabs(prediction - targets[sample]) < 0.1f) correct++;
                }
                float accuracy = (float)correct / 4.0f;
                
                if (accuracy > best_accuracy) best_accuracy = accuracy;
                if (accuracy >= 0.95f) {
                    converged = 1;
                    printf("   ‚úÖ Converg√© en %d √©poques (%.1f%%)\n", epoch, accuracy * 100);
                }
            }
        }
        
        if (!converged) {
            printf("   ‚ö†Ô∏è Non converg√© - Best: %.1f%%\n", best_accuracy * 100);
        }
        
        network_free_simple(network);
    }
    
    printf("\nüèÜ Test de toutes les activations termin√© !\n");
    return 0;
}

// Impl√©mentation du test de tous les optimiseurs
int test_all_optimizers() {
    printf("‚ö° TEST COMPLET DE TOUS LES OPTIMISEURS\n");
    printf("======================================\n\n");
    
    const char *optimizers[] = {
        "sgd", "adam", "adamw", "rmsprop", 
        "lion", "adabelief", "radam", "adamax", "nadam"
    };
    int num_optimizers = sizeof(optimizers) / sizeof(optimizers[0]);
    
    printf("üèóÔ∏è Architecture fixe : Input(2)‚Üí256‚Üí128‚ÜíOutput(1)\n");
    printf("üéØ Activation fixe : ReLU + ReLU + Sigmoid\n");
    printf("üìä Dataset : XOR (4 √©chantillons)\n");
    printf("üìà M√©trique : Vitesse de convergence\n\n");
    
    for (int i = 0; i < num_optimizers; i++) {
        printf("üß™ Test optimiseur %d/%d : %s\n", i+1, num_optimizers, optimizers[i]);
        
        size_t layer_sizes[] = {2, 256, 128, 1};
        const char *activations[] = {"relu", "relu", "sigmoid"};
        NeuralNetwork *network = network_create_simple(4, layer_sizes, activations);
        
        if (!network) {
            printf("‚ùå Erreur cr√©ation r√©seau pour %s\n", optimizers[i]);
            continue;
        }
        
        // Simuler diff√©rents learning rates selon l'optimiseur
        float learning_rate = 0.001f;
        if (strcmp(optimizers[i], "sgd") == 0) learning_rate = 0.01f;
        if (strcmp(optimizers[i], "lion") == 0) learning_rate = 0.0001f;
        
        int convergence_epoch = -1;
        
        for (int epoch = 0; epoch < 200; epoch++) {
            // XOR entra√Ænement
            float inputs[4][2] = {{0,0}, {0,1}, {1,0}, {1,1}};
            float targets[4] = {0, 1, 1, 0};
            
            for (int sample = 0; sample < 4; sample++) {
                network_forward_simple(network, inputs[sample]);
                float target_array[] = {targets[sample]};
                network_backward_simple(network, inputs[sample], target_array, learning_rate);
            }
            
            // Test convergence
            if (epoch % 5 == 0) {
                int correct = 0;
                for (int sample = 0; sample < 4; sample++) {
                    network_forward_simple(network, inputs[sample]);
                    float *output = network_output_simple(network);
                    float prediction = output[0] > 0.5f ? 1.0f : 0.0f;
                    if (fabs(prediction - targets[sample]) < 0.1f) correct++;
                }
                
                if (correct == 4 && convergence_epoch == -1) {
                    convergence_epoch = epoch;
                    printf("   ‚úÖ Converg√© en %d √©poques (LR=%.4f)\n", epoch, learning_rate);
                    break;
                }
            }
        }
        
        if (convergence_epoch == -1) {
            printf("   ‚ö†Ô∏è Non converg√© en 200 √©poques (LR=%.4f)\n", learning_rate);
        }
        
        network_free_simple(network);
    }
    
    printf("\nüèÜ Test de tous les optimiseurs termin√© !\n");
    return 0;
}

// Impl√©mentation du test des m√©thodes neuroplast
int test_neuroplast_methods() {
    printf("üß† TEST COMPLET DES M√âTHODES NEUROPLAST\n");
    printf("=======================================\n\n");
    
    const char *neuroplast_methods[] = {
        "standard", "adaptive", "advanced", "bayesian", 
        "progressive", "swarm", "propagation"
    };
    int num_methods = sizeof(neuroplast_methods) / sizeof(neuroplast_methods[0]);
    
    printf("üèóÔ∏è Architecture : Input(2)‚Üí256‚Üí128‚ÜíOutput(1)\n");
    printf("üéØ Activation : NeuroPlast + NeuroPlast + Sigmoid\n");
    printf("‚ö° Optimiseur : AdamW adaptatif\n");
    printf("üìä Dataset : XOR complexe\n\n");
    
    for (int i = 0; i < num_methods; i++) {
        printf("üß™ Test m√©thode %d/%d : %s\n", i+1, num_methods, neuroplast_methods[i]);
        
        size_t layer_sizes[] = {2, 256, 128, 1};
        const char *activations[] = {"neuroplast", "neuroplast", "sigmoid"};
        NeuralNetwork *network = network_create_simple(4, layer_sizes, activations);
        
        if (!network) {
            printf("‚ùå Erreur cr√©ation r√©seau pour %s\n", neuroplast_methods[i]);
            continue;
        }
        
        // Param√®tres adaptatifs selon la m√©thode
        float learning_rate = 0.001f;
        int max_epochs = 150;
        
        if (strcmp(neuroplast_methods[i], "advanced") == 0) {
            learning_rate = 0.002f; // Plus agressif
        } else if (strcmp(neuroplast_methods[i], "bayesian") == 0) {
            max_epochs = 200; // Plus de temps pour optimisation
        } else if (strcmp(neuroplast_methods[i], "swarm") == 0) {
            learning_rate = 0.0005f; // Plus conservateur
        }
        
        float best_accuracy = 0.0f;
        int best_epoch = -1;
        
        for (int epoch = 0; epoch < max_epochs; epoch++) {
            // XOR entra√Ænement
            float inputs[4][2] = {{0,0}, {0,1}, {1,0}, {1,1}};
            float targets[4] = {0, 1, 1, 0};
            
            for (int sample = 0; sample < 4; sample++) {
                network_forward_simple(network, inputs[sample]);
                float target_array[] = {targets[sample]};
                network_backward_simple(network, inputs[sample], target_array, learning_rate);
            }
            
            // √âvaluation p√©riodique
            if (epoch % 10 == 0) {
                int correct = 0;
                float total_loss = 0.0f;
                
                for (int sample = 0; sample < 4; sample++) {
                    network_forward_simple(network, inputs[sample]);
                    float *output = network_output_simple(network);
                    float prediction = output[0] > 0.5f ? 1.0f : 0.0f;
                    
                    if (fabs(prediction - targets[sample]) < 0.1f) correct++;
                    
                    float error = output[0] - targets[sample];
                    total_loss += error * error;
                }
                
                float accuracy = (float)correct / 4.0f;
                if (accuracy > best_accuracy) {
                    best_accuracy = accuracy;
                    best_epoch = epoch;
                }
                
                if (accuracy >= 1.0f) {
                    printf("   ‚úÖ Convergence parfaite en %d √©poques (Loss=%.6f)\n", 
                           epoch, total_loss/4.0f);
                    break;
                }
            }
        }
        
        printf("   üìä Meilleure accuracy: %.1f%% (√©poque %d)\n", 
               best_accuracy * 100, best_epoch);
        
        network_free_simple(network);
    }
    
    printf("\nüèÜ Test de toutes les m√©thodes neuroplast termin√© !\n");
    return 0;
}

// Impl√©mentation du test complet de toutes les combinaisons
int test_complete_combinations() {
    printf("üöÄ TEST COMPLET DE TOUTES LES COMBINAISONS\n");
    printf("==========================================\n\n");
    
    const char *activations[] = {"neuroplast", "gelu", "relu", "mish"};
    const char *optimizers[] = {"adamw", "adam", "radam", "lion"};
    const char *methods[] = {"advanced", "bayesian", "swarm"};
    
    int num_activations = 4;
    int num_optimizers = 4;
    int num_methods = 3;
    int total_combinations = num_activations * num_optimizers * num_methods;
    
    printf("üéØ %d combinaisons √† tester\n", total_combinations);
    printf("üèóÔ∏è Architecture : Input(2)‚Üí256‚Üí128‚ÜíOutput(1)\n");
    printf("üìä Dataset : XOR (convergence rapide)\n");
    printf("‚è±Ô∏è Limite : 50 √©poques par test\n\n");
    
    int combination = 0;
    int best_combination = -1;
    float best_score = 0.0f;
    
    for (int a = 0; a < num_activations; a++) {
        for (int o = 0; o < num_optimizers; o++) {
            for (int m = 0; m < num_methods; m++) {
                combination++;
                
                char combo_info[256];
                snprintf(combo_info, sizeof(combo_info), 
                        "üß™ Combinaison %d/%d : %s + %s + %s", 
                        combination, total_combinations,
                        activations[a], optimizers[o], methods[m]);
                print_info_safe(combo_info);
                
                size_t layer_sizes[] = {2, 256, 128, 1};
                const char *test_activations[] = {activations[a], activations[a], "sigmoid"};
                NeuralNetwork *network = network_create_simple(4, layer_sizes, test_activations);
                
                if (!network) {
                    printf("   ‚ùå Erreur cr√©ation r√©seau\n");
                    continue;
                }
                
                // Learning rate adaptatif selon l'optimiseur
                float lr = 0.001f;
                if (strcmp(optimizers[o], "lion") == 0) lr = 0.0001f;
                if (strcmp(optimizers[o], "adamw") == 0) lr = 0.002f;
                
                float final_accuracy = 0.0f;
                int convergence_epoch = -1;
                
                for (int epoch = 0; epoch < 50; epoch++) {
                    // XOR training
                    float inputs[4][2] = {{0,0}, {0,1}, {1,0}, {1,1}};
                    float targets[4] = {0, 1, 1, 0};
                    
                    for (int sample = 0; sample < 4; sample++) {
                        network_forward_simple(network, inputs[sample]);
                        float target_array[] = {targets[sample]};
                        network_backward_simple(network, inputs[sample], target_array, lr);
                    }
                    
                    // Test final
                    if (epoch == 49) {
                        int correct = 0;
                        for (int sample = 0; sample < 4; sample++) {
                            network_forward_simple(network, inputs[sample]);
                            float *output = network_output_simple(network);
                            float prediction = output[0] > 0.5f ? 1.0f : 0.0f;
                            if (fabs(prediction - targets[sample]) < 0.1f) correct++;
                        }
                        final_accuracy = (float)correct / 4.0f;
                    }
                    
                    // D√©tection convergence pr√©coce
                    if (epoch % 10 == 0) {
                        int correct = 0;
                        for (int sample = 0; sample < 4; sample++) {
                            network_forward_simple(network, inputs[sample]);
                            float *output = network_output_simple(network);
                            float prediction = output[0] > 0.5f ? 1.0f : 0.0f;
                            if (fabs(prediction - targets[sample]) < 0.1f) correct++;
                        }
                        if (correct == 4 && convergence_epoch == -1) {
                            convergence_epoch = epoch;
                        }
                    }
                }
                
                // Score composite : accuracy + vitesse de convergence
                float score = final_accuracy;
                if (convergence_epoch != -1) {
                    score += (50 - convergence_epoch) / 50.0f; // Bonus vitesse
                }
                
                printf("   üìä Accuracy: %.1f%% | Convergence: %s | Score: %.3f\n",
                       final_accuracy * 100,
                       convergence_epoch != -1 ? "‚úÖ" : "‚ö†Ô∏è",
                       score);
                
                if (score > best_score) {
                    best_score = score;
                    best_combination = combination;
                }
                
                network_free_simple(network);
            }
        }
    }
    
    printf("\nüèÜ MEILLEURE COMBINAISON : Test %d (Score: %.3f)\n", 
           best_combination, best_score);
    printf("üéØ Test complet termin√© !\n");
    return 0;
}

// Test exhaustif avec dataset r√©el (appel√© depuis main pour compare_all_methods)
int test_all_with_real_dataset(const char **neuroplast_methods, int num_methods,
                               const char **optimizers, int num_optimizers,
                               const char **activations, int num_activations,
                               const char *config_path, int max_epochs) {
    printf("üöÄ TEST EXHAUSTIF AVEC DATASET R√âEL\n");
    printf("=====================================\n\n");
    
    int total_combinations = num_methods * num_optimizers * num_activations;
    
    printf("üéØ TEST EXHAUSTIF COMPLET :\n");
    printf("   üìä %d m√©thodes neuroplast\n", num_methods);
    printf("   ‚ö° %d optimiseurs\n", num_optimizers); 
    printf("   üéØ %d fonctions d'activation\n", num_activations);
    printf("   üöÄ %d combinaisons TOTALES\n", total_combinations);
    printf("   üîÑ 3 essais par combinaison\n");
    printf("   üìà %d √©poques max par essai\n\n", max_epochs);
    
    printf("‚è±Ô∏è Dur√©e estim√©e : 45-60 minutes (mode exhaustif avec dataset r√©el)\n");
    printf("üìä Architecture : Input‚Üí256‚Üí128‚ÜíOutput\n");
    printf("üéØ Dataset : %s\n\n", config_path);
    
    // Charger la configuration depuis le fichier YAML
    RichConfig dataset_config;
    memset(&dataset_config, 0, sizeof(RichConfig));
    
    printf("üîß Chargement de la configuration depuis: %s\n", config_path);
    
    if (!parse_yaml_rich_config(config_path, &dataset_config)) {
        printf("‚ö†Ô∏è Impossible de charger la configuration depuis %s\n", config_path);
        printf("‚ö†Ô∏è Cr√©ation d'un dataset simul√© √† la place\n");
        
        // Initialiser une configuration par d√©faut pour dataset simul√©
        dataset_config.is_image_dataset = 0;  // Dataset tabulaire
        dataset_config.input_cols = 8;
        dataset_config.output_cols = 1;
        strcpy(dataset_config.dataset_name, "simulated"); // Nom par d√©faut pour dataset simul√©
    } else {
        printf("‚úÖ Configuration charg√©e avec succ√®s\n");
        printf("üìä Dataset name lu: '%s'\n", dataset_config.dataset_name);
        printf("üìä Is image dataset: %d\n", dataset_config.is_image_dataset);
        printf("üìä Dataset path: '%s'\n", dataset_config.dataset);
    }
    
    // Charger le dataset selon la configuration (images ou tabulaire)
    // üÜï NOUVEAU SYST√àME D'ANALYSE AUTOMATIQUE DES DATASETS TABULAIRES
    printf("\nüîç SYST√àME D'ANALYSE AUTOMATIQUE DES DATASETS\n");
    printf("=============================================\n");
    
    Dataset *dataset = create_analyzed_dataset(&dataset_config);
    if (!dataset) {
        printf("‚ùå √âchec du syst√®me d'analyse automatique\n");
        printf("‚ùå Impossible de cr√©er un dataset, arr√™t du test\n");
        return 1;
    }
    
    printf("‚úÖ Dataset charg√©: %zu samples, %zu inputs, %zu outputs\n", 
           dataset->num_samples, dataset->input_cols, dataset->output_cols);
    
    // Division train/test
    Dataset *train_set = NULL, *test_set = NULL;
    split_dataset(dataset, 0.8f, &train_set, &test_set);
    
    printf("‚úÖ Division train/test - Train: %zu, Test: %zu\n", 
           train_set->num_samples, test_set->num_samples);
    
    // üéØ INITIALISER LE SYST√àME DE SAUVEGARDE DES 10 MEILLEURS MOD√àLES
    printf("üîß Initialisation du syst√®me de sauvegarde des 10 meilleurs mod√®les...\n");
    
    // Utiliser le dataset_name de la configuration pour cr√©er un r√©pertoire sp√©cifique
    const char *dataset_name = (strlen(dataset_config.dataset_name) > 0) ? dataset_config.dataset_name : "default";
    if (init_best_models_manager_with_dataset("./best_models_neuroplast", dataset_name) != 0) {
        printf("‚ö†Ô∏è Erreur: Impossible d'initialiser le gestionnaire, continuons sans sauvegarde\n");
    } else {
        printf("üíæ Sauvegarde automatique des 10 meilleurs mod√®les activ√©e\n");
    }
    
    // Initialiser le syst√®me d'affichage dual zone (NOUVELLE APPROCHE)
    progress_init_dual_zone(
        "Test exhaustif avec dataset r√©el - 3 essais par combinaison", 
        total_combinations,
        3,  // 3 essais par combinaison
        max_epochs  // √©poques max par essai
    );
    
    // Cr√©er les barres de progression hi√©rarchiques
    int general_bar = progress_global_add(PROGRESS_GENERAL, "Test Exhaustif Complet", total_combinations, 40);
    int trials_bar = progress_global_add(PROGRESS_TRIALS, "Essais par Combinaison", 3, 25);
    int epochs_bar = progress_global_add(PROGRESS_EPOCHS, "Epoques par Essai", max_epochs, 20);
    
    print_info_safe("üéØ Syst√®me de progression dual zone initialis√© pour test exhaustif");
    print_info_safe("üìä Zone des barres: Lignes 11-14 | Zone des infos: Ligne 19+");
    
    // Variables pour collecter les r√©sultats de TOUTES les combinaisons avec toutes les m√©triques
    typedef struct {
        char method[32];
        char optimizer[32];
        char activation[32];
        char full_name[128];
        // M√©triques moyennes sur tous les essais
        float avg_accuracy;
        float avg_precision;
        float avg_recall;
        float avg_f1_score;
        float avg_auc_roc;
        // Meilleures m√©triques obtenues
        float best_accuracy;
        float best_precision;
        float best_recall;
        float best_f1_score;
        float best_auc_roc;
        // Informations de convergence
        int convergence_count;
        int total_trials;
        float convergence_rate;
    } CombinationResult;
    
    CombinationResult *results = malloc(total_combinations * sizeof(CombinationResult));
    if (!results) {
        printf("‚ùå Erreur allocation m√©moire pour %d combinaisons\n", total_combinations);
        dataset_free(dataset);
        dataset_free(train_set);
        dataset_free(test_set);
        return 1;
    }
    
    int result_count = 0;
    int combination_count = 0;
    
    printf("üöÄ D√âMARRAGE DU TEST EXHAUSTIF AVEC DATASET R√âEL...\n\n");
    
    // BOUCLE TRIPLE : TOUTES LES COMBINAISONS
    for (int m = 0; m < num_methods; m++) {
        for (int o = 0; o < num_optimizers; o++) {
            for (int a = 0; a < num_activations; a++) {
                combination_count++;
                
                // AFFICHAGE ORGANIS√â DE L'EN-T√äTE DE COMBINAISON
                progress_display_combination_header(combination_count, total_combinations,
                                                  neuroplast_methods[m], optimizers[o], activations[a]);
                
                // Variables pour moyenner sur plusieurs essais - toutes les m√©triques
                AllMetrics total_metrics = {0};  // Somme de toutes les m√©triques
                AllMetrics best_metrics = {0};   // Meilleures m√©triques obtenues
                int convergence_count = 0;
                int trials = 5; // 3 ‚Üí 5 essais par combinaison pour plus de stabilit√©
                
                // R√©initialiser la barre des essais pour cette combinaison
                progress_global_update(trials_bar, 0, 0.0f, 0.0f, 0.0f);
                
                for (int trial = 0; trial < trials; trial++) {
                    // ARCHITECTURES VARI√âES selon la combinaison (NOUVEAU!)
                    size_t layer_sizes[5];
                    const char *test_activations[4];
                    int num_layers;
                    
                    // Choix d'architecture selon l'optimiseur et l'activation
                    int arch_variant = (o * num_activations + a) % 6; // 6 architectures diff√©rentes
                    
                    switch(arch_variant) {
                        case 0: // Architecture optimis√©e minimaliste
                            layer_sizes[0] = 8;   // 8 features m√©dicales
                            layer_sizes[1] = 128; // 64 ‚Üí 128 (doubl√©)
                            layer_sizes[2] = 64;  // Ajout d'une couche
                            layer_sizes[3] = 1;   // Classification binaire
                            test_activations[0] = activations[a];
                            test_activations[1] = activations[a];
                            test_activations[2] = "sigmoid";
                            num_layers = 4; // 3 ‚Üí 4 couches
                            break;
                            
                        case 1: // Architecture √©quilibr√©e optimis√©e
                            layer_sizes[0] = 8;
                            layer_sizes[1] = 256; // 128 ‚Üí 256
                            layer_sizes[2] = 128; // 64 ‚Üí 128
                            layer_sizes[3] = 64;  // Ajout d'une couche
                            layer_sizes[4] = 1;
                            test_activations[0] = activations[a];
                            test_activations[1] = activations[a];
                            test_activations[2] = activations[a];
                            test_activations[3] = "sigmoid";
                            num_layers = 5; // 4 ‚Üí 5 couches
                            break;
                            
                        case 2: // Architecture large optimis√©e
                            layer_sizes[0] = 8;
                            layer_sizes[1] = 512; // 256 ‚Üí 512
                            layer_sizes[2] = 256; // 128 ‚Üí 256
                            layer_sizes[3] = 128; // Ajout d'une couche
                            layer_sizes[4] = 1;
                            test_activations[0] = activations[a];
                            test_activations[1] = activations[a];
                            test_activations[2] = activations[a];
                            test_activations[3] = "sigmoid";
                            num_layers = 5; // 4 ‚Üí 5 couches
                            break;
                            
                        case 3: // Architecture profonde ultra-optimis√©e
                            layer_sizes[0] = 8;
                            layer_sizes[1] = 256; // 128 ‚Üí 256
                            layer_sizes[2] = 128; // 64 ‚Üí 128
                            layer_sizes[3] = 64;  // 32 ‚Üí 64
                            layer_sizes[4] = 1;
                            test_activations[0] = activations[a];
                            test_activations[1] = activations[a];
                            test_activations[2] = activations[a];
                            test_activations[3] = "sigmoid";
                            num_layers = 5;
                            break;
                            
                        case 4: // Architecture √©troite mais plus profonde
                            layer_sizes[0] = 8;
                            layer_sizes[1] = 64;  // 32 ‚Üí 64
                            layer_sizes[2] = 32;  // 16 ‚Üí 32
                            layer_sizes[3] = 16;  // Ajout d'une couche
                            layer_sizes[4] = 1;
                            test_activations[0] = activations[a];
                            test_activations[1] = activations[a];
                            test_activations[2] = activations[a];
                            test_activations[3] = "sigmoid";
                            num_layers = 5; // 4 ‚Üí 5 couches
                            break;
                            
                        default: // Architecture tr√®s large ultra-optimis√©e (cas 5)
                            layer_sizes[0] = 8;
                            layer_sizes[1] = 1024; // 512 ‚Üí 1024
                            layer_sizes[2] = 512;  // 256 ‚Üí 512
                            layer_sizes[3] = 256;  // Ajout d'une couche
                            layer_sizes[4] = 1;
                            test_activations[0] = activations[a];
                            test_activations[1] = activations[a];
                            test_activations[2] = activations[a];
                            test_activations[3] = "sigmoid";
                            num_layers = 5; // 4 ‚Üí 5 couches
                            break;
                    }
                    
                    // Cr√©ation du r√©seau avec architecture variable
                    NeuralNetwork *network = network_create_simple(num_layers, layer_sizes, test_activations);
                    if (!network) {
                        print_info_safe("‚ùå Erreur cr√©ation r√©seau");
                        continue;
                    }
                    
                    // Learning rate adaptatif selon l'optimiseur ET l'architecture (OPTIMIS√â POUR >95% ACCURACY!)
                    float lr = 0.003f; // üîß CORRECTION: Base r√©duite de 0.01 √† 0.003 (comme version qui fonctionnait)
                    
                    // Ajustement selon l'optimiseur (OPTIMIS√â)
                    if (strcmp(optimizers[o], "sgd") == 0) lr = 0.015f;        // 0.05 ‚Üí 0.015
                    else if (strcmp(optimizers[o], "lion") == 0) lr = 0.0003f; // 0.001 ‚Üí 0.0003
                    else if (strcmp(optimizers[o], "adamw") == 0) lr = 0.005f; // 0.015 ‚Üí 0.005
                    else if (strcmp(optimizers[o], "adam") == 0) lr = 0.004f;  // 0.012 ‚Üí 0.004
                    else if (strcmp(optimizers[o], "rmsprop") == 0) lr = 0.002f; // 0.008 ‚Üí 0.002
                    else if (strcmp(optimizers[o], "adabelief") == 0) lr = 0.003f; // 0.01 ‚Üí 0.003
                    else if (strcmp(optimizers[o], "radam") == 0) lr = 0.0035f;   // 0.01 ‚Üí 0.0035
                    else if (strcmp(optimizers[o], "adamax") == 0) lr = 0.006f;   // 0.018 ‚Üí 0.006
                    else if (strcmp(optimizers[o], "nadam") == 0) lr = 0.0045f;   // 0.013 ‚Üí 0.0045
                    
                    // Ajustement selon l'architecture pour plus de variation (OPTIMIS√â)
                    switch(arch_variant) {
                        case 0: lr *= 1.2f; break;  // Architecture minimaliste - moins agressif (1.5 ‚Üí 1.2)
                        case 1: lr *= 1.0f; break;  // Architecture √©quilibr√©e - standard
                        case 2: lr *= 0.9f; break;  // Architecture large - un peu plus conservateur (0.8 ‚Üí 0.9)
                        case 3: lr *= 0.7f; break;  // Architecture profonde - conservateur (0.6 ‚Üí 0.7)
                        case 4: lr *= 1.3f; break;  // Architecture √©troite - mod√©r√©ment agressif (2.0 ‚Üí 1.3)
                        case 5: lr *= 0.5f; break;  // Architecture tr√®s large - tr√®s conservateur (0.4 ‚Üí 0.5)
                    }
                    
                    // Ajustement selon la fonction d'activation (OPTIMIS√â)
                    if (strcmp(activations[a], "relu") == 0) lr *= 1.0f;        // 1.1 ‚Üí 1.0
                    else if (strcmp(activations[a], "gelu") == 0) lr *= 0.95f;   // 0.9 ‚Üí 0.95
                    else if (strcmp(activations[a], "sigmoid") == 0) lr *= 1.1f; // 1.3 ‚Üí 1.1
                    else if (strcmp(activations[a], "neuroplast") == 0) lr *= 0.9f; // 0.8 ‚Üí 0.9
                    else if (strcmp(activations[a], "mish") == 0) lr *= 0.9f;    // 0.85 ‚Üí 0.9
                    else if (strcmp(activations[a], "swish") == 0) lr *= 1.0f;   // 0.95 ‚Üí 1.0
                    
                    // AFFICHAGE ORGANIS√â DES INFORMATIONS DU R√âSEAU
                    char architecture[128];
                    snprintf(architecture, sizeof(architecture), "Input(%zu)", layer_sizes[0]);
                    for (int i = 1; i < num_layers; i++) {
                        char layer_str[32];
                        snprintf(layer_str, sizeof(layer_str), "‚Üí%zu", layer_sizes[i]);
                        strcat(architecture, layer_str);
                    }
                    
                    char dataset_info[128];
                    const char *dataset_display_name = "Dataset";
                    if (strlen(dataset_config.dataset_name) > 0) {
                        dataset_display_name = dataset_config.dataset_name;
                    } else if (strlen(dataset_config.dataset) > 0) {
                        dataset_display_name = dataset_config.dataset;
                    }
                    snprintf(dataset_info, sizeof(dataset_info), "%s (%zu √©chantillons)", dataset_display_name, dataset->num_samples);
                    
                    // Class weights adaptatifs selon la m√©thode neuroplast (OPTIMIS√â POUR >95%)
                    float class_weights[2] = {1.0f, 1.0f}; // √âquilibr√© par d√©faut
                    if (strcmp(neuroplast_methods[m], "adaptive") == 0) {
                        class_weights[0] = 0.85f; class_weights[1] = 1.15f; // 0.8/1.2 ‚Üí 0.85/1.15
                    } else if (strcmp(neuroplast_methods[m], "bayesian") == 0) {
                        class_weights[0] = 0.95f; class_weights[1] = 1.05f; // 0.9/1.1 ‚Üí 0.95/1.05
                    } else if (strcmp(neuroplast_methods[m], "swarm") == 0) {
                        class_weights[0] = 1.05f; class_weights[1] = 0.95f; // 1.1/0.9 ‚Üí 1.05/0.95
                    } else if (strcmp(neuroplast_methods[m], "advanced") == 0) {
                        class_weights[0] = 0.9f; class_weights[1] = 1.1f;   // Nouveau
                    } else if (strcmp(neuroplast_methods[m], "progressive") == 0) {
                        class_weights[0] = 1.02f; class_weights[1] = 0.98f; // Nouveau
                    } else if (strcmp(neuroplast_methods[m], "propagation") == 0) {
                        class_weights[0] = 0.98f; class_weights[1] = 1.02f; // Nouveau
                    }
                    
                    progress_display_network_info(architecture, dataset_info, lr, class_weights);
                    
                    AllMetrics trial_best_metrics = {0};  // Meilleures m√©triques pour cet essai
                    int trial_convergence = 0;
                    int convergence_epoch = -1;  // √âpoque de convergence pour cet essai
                    float current_loss = 1.0f;
                    
                    // üîß CORRECTION MAJEURE: Variables pour early stopping (D√âPLAC√âES HORS DE LA BOUCLE)
                    float best_f1_score = 0.0f;
                    int patience_counter = 0;
                    
                    // R√©initialiser la barre des √©poques pour cet essai
                    progress_global_update(epochs_bar, 0, 0.0f, 0.0f, 0.0f);
                    
                    // Entra√Ænement avec affichage des m√©triques toutes les 5 √©poques
                    for (int epoch = 0; epoch < max_epochs; epoch++) {
                        current_loss = 0.0f;
                        int should_stop_early = 0;
                        
                        // Entra√Ænement sur tout le dataset d'entra√Ænement (MULTI-PASS POUR OPTIMISATION)
                        for (int pass = 0; pass < 2; pass++) { // 2 passages par √©poque pour meilleur apprentissage
                            for (size_t i = 0; i < train_set->num_samples; i++) {
                                // ENTRA√éNEMENT POUR TOUTES LES M√âTHODES NEUROPLAST
                                network_forward_simple(network, train_set->inputs[i]);
                                network_backward_simple(network, train_set->inputs[i], train_set->outputs[i], lr);
                                
                                // üîß CORRECTION: Revenir au calcul MSE qui fonctionnait (seulement au premier passage)
                                if (pass == 0) {
                                    float *output = network_output_simple(network);
                                    if (output) {
                                        float error = output[0] - train_set->outputs[i][0];
                                        current_loss += error * error;
                                    }
                                }
                            }
                        }
                        
                        // Normaliser le loss par le nombre d'√©chantillons
                        current_loss = current_loss / train_set->num_samples;
                        
                        // Calcul des m√©triques toutes les 5 √©poques OU si early stopping activ√©
                        if (epoch % 5 == 0 || epoch == max_epochs - 1 || dataset_config.early_stopping) {
                            AllMetrics test_metrics = compute_all_metrics(network, test_set, &dataset_config);
                            
                            // Mettre √† jour les meilleures m√©triques pour cet essai
                            if (test_metrics.f1_score > trial_best_metrics.f1_score) {
                                trial_best_metrics = test_metrics;
                            }
                            
                            // üîß EARLY STOPPING SIMPLIFI√â (comme dans la version qui fonctionnait)
                            if (dataset_config.early_stopping && epoch > 10) { // Attendre au moins 10 √©poques
                                if (test_metrics.f1_score > best_f1_score + 0.01f) { // Am√©lioration significative
                                    best_f1_score = test_metrics.f1_score;
                                    patience_counter = 0;
                                } else {
                                    patience_counter++;
                                    if (patience_counter >= dataset_config.patience && best_f1_score > 0.1f) {
                                        should_stop_early = 1;
                                        printf("üõë Early stopping √† l'√©poque %d (patience: %d, meilleur F1: %.3f)\n", 
                                               epoch, dataset_config.patience, best_f1_score);
                                    }
                                }
                            }
                            
                            if (test_metrics.f1_score >= 0.90f && !trial_convergence) { // Convergence √† 90% F1
                                trial_convergence = 1;
                                convergence_epoch = epoch;
                            }
                            
                            // AFFICHAGE ORGANIS√â DES INFORMATIONS D'√âPOQUE
                            if (epoch % 5 == 0 || epoch == max_epochs - 1) {
                                progress_display_epoch_info(epoch, max_epochs, current_loss, 
                                                           test_metrics.accuracy, test_metrics.precision,
                                                           test_metrics.recall, test_metrics.f1_score);
                            }
                            
                            // Mettre √† jour la barre des √©poques avec m√©triques toutes les 5 √©poques
                            progress_global_update(epochs_bar, epoch + 1, current_loss, test_metrics.f1_score, lr);
                        }
                        
                        // Early stopping pour √©viter l'overfitting (simplifi√©)
                        if (should_stop_early || (trial_convergence && epoch > max_epochs / 3)) {
                            if (should_stop_early) {
                                print_info_safe("üõë Arr√™t pr√©coce par early stopping");
                            } else {
                                print_info_safe("‚úÖ Convergence pr√©coce d√©tect√©e");
                            }
                            break;
                        }
                    }
                    
                    // üéØ √âVALUER ET SAUVEGARDER LE MOD√àLE AVEC NOTRE SYST√àME INT√âGR√â
                    // Calculer les m√©triques finales pour la sauvegarde
                    AllMetrics final_metrics = compute_all_metrics(network, test_set, &dataset_config);
                    AllMetrics train_metrics = compute_all_metrics(network, train_set, &dataset_config);
                    
                    // Cr√©er le nom du mod√®le
                    char model_name[128];
                    snprintf(model_name, sizeof(model_name), "%s+%s+%s", 
                            neuroplast_methods[m], optimizers[o], activations[a]);
                    
                    // Ajouter ce mod√®le aux candidats pour le top 10
                    int save_result = add_candidate_model(
                        model_name,
                        optimizers[o],
                        neuroplast_methods[m], 
                        activations[a],
                        train_metrics.accuracy,
                        current_loss,
                        final_metrics.accuracy,
                        1.0f - final_metrics.f1_score, // Approximation de la validation loss
                        final_metrics.f1_score,
                        lr,
                        combination_count * 1000 + trial
                    );
                    
                    if (save_result == 1) {
                        char save_info[256];
                        snprintf(save_info, sizeof(save_info), 
                                "üèÜ Mod√®le %s ajout√© au TOP 10! F1=%.1f%% Acc=%.1f%%", 
                                model_name, 
                                final_metrics.f1_score * 100, 
                                final_metrics.accuracy * 100);
                        print_info_safe(save_info);
                    }
                    
                    // Ajouter les m√©triques de cet essai aux totaux
                    total_metrics.accuracy += trial_best_metrics.accuracy;
                    total_metrics.precision += trial_best_metrics.precision;
                    total_metrics.recall += trial_best_metrics.recall;
                    total_metrics.f1_score += trial_best_metrics.f1_score;
                    total_metrics.auc_roc += trial_best_metrics.auc_roc;
                    
                    // Mettre √† jour les meilleures m√©triques globales si n√©cessaire
                    if (trial_best_metrics.accuracy > best_metrics.accuracy) best_metrics.accuracy = trial_best_metrics.accuracy;
                    if (trial_best_metrics.precision > best_metrics.precision) best_metrics.precision = trial_best_metrics.precision;
                    if (trial_best_metrics.recall > best_metrics.recall) best_metrics.recall = trial_best_metrics.recall;
                    if (trial_best_metrics.f1_score > best_metrics.f1_score) best_metrics.f1_score = trial_best_metrics.f1_score;
                    if (trial_best_metrics.auc_roc > best_metrics.auc_roc) best_metrics.auc_roc = trial_best_metrics.auc_roc;
                    
                    if (trial_convergence) convergence_count++;
                    
                    // AFFICHAGE ORGANIS√â DU R√âSUM√â D'ESSAI
                    progress_display_trial_summary(trial, trials, trial_best_metrics.accuracy, 
                                                  trial_best_metrics.f1_score, convergence_epoch);
                    
                    // Mettre √† jour la barre des essais
                    float trial_loss = (trial_best_metrics.f1_score > 0) ? (1.0f - trial_best_metrics.f1_score) : current_loss;
                    progress_global_update(trials_bar, trial + 1, trial_loss, trial_best_metrics.f1_score, lr);
                    
                    network_free_simple(network);
                }
                
                // Stocker le r√©sultat de cette combinaison avec toutes les m√©triques
                strcpy(results[result_count].method, neuroplast_methods[m]);
                strcpy(results[result_count].optimizer, optimizers[o]);
                strcpy(results[result_count].activation, activations[a]);
                snprintf(results[result_count].full_name, sizeof(results[result_count].full_name),
                        "%s+%s+%s", neuroplast_methods[m], optimizers[o], activations[a]);
                
                // Calculer les moyennes pour chaque m√©trique
                results[result_count].avg_accuracy = total_metrics.accuracy / trials;
                results[result_count].avg_precision = total_metrics.precision / trials;
                results[result_count].avg_recall = total_metrics.recall / trials;
                results[result_count].avg_f1_score = total_metrics.f1_score / trials;
                results[result_count].avg_auc_roc = total_metrics.auc_roc / trials;
                
                // Sauvegarder les meilleures m√©triques
                results[result_count].best_accuracy = best_metrics.accuracy;
                results[result_count].best_precision = best_metrics.precision;
                results[result_count].best_recall = best_metrics.recall;
                results[result_count].best_f1_score = best_metrics.f1_score;
                results[result_count].best_auc_roc = best_metrics.auc_roc;
                results[result_count].convergence_count = convergence_count;
                results[result_count].total_trials = trials;
                results[result_count].convergence_rate = (float)convergence_count / trials;
                
                // AFFICHAGE ORGANIS√â DU R√âSUM√â DE COMBINAISON
                progress_display_combination_summary(results[result_count].avg_f1_score, 
                                                   results[result_count].best_f1_score,
                                                   convergence_count, trials);
                
                result_count++;
                
                // Mettre √† jour la barre de progression g√©n√©rale
                float avg_loss = (results[result_count-1].avg_f1_score > 0) ? (1.0f - results[result_count-1].avg_f1_score) : 1.0f;
                float current_accuracy = results[result_count-1].avg_f1_score;
                progress_global_update(general_bar, combination_count, avg_loss, current_accuracy, 0.001f);
                
                // Pr√©parer l'affichage pour la prochaine combinaison
                progress_prepare_next_combination();
            }
        }
    }
    
    // ANALYSE DES R√âSULTATS EXHAUSTIFS (m√™me logique que test_all())
    printf("\nüî∏ ANALYSE DES R√âSULTATS EXHAUSTIFS (DATASET R√âEL)\n");
    printf("===================================================\n\n");
    
    printf("üèÜ ANALYSE COMPL√àTE DE %d COMBINAISONS\n", total_combinations);
    printf("====================================\n\n");
    
    // Trier par score moyen (bubble sort)
    for (int i = 0; i < result_count - 1; i++) {
        for (int j = 0; j < result_count - i - 1; j++) {
            if (results[j].avg_f1_score < results[j + 1].avg_f1_score) {
                CombinationResult temp = results[j];
                results[j] = results[j + 1];
                results[j + 1] = temp;
            }
        }
    }
    
    // TOP 10 des meilleures combinaisons
    printf("ü•á TOP 10 DES MEILLEURES COMBINAISONS (TOUTES M√âTRIQUES) :\n");
    printf("‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n");
    printf("Rang | Combinaison                          | Accuracy | Precision | Recall | F1-Score | AUC-ROC | Conv %%\n");
    printf("-----|--------------------------------------|----------|-----------|--------|----------|---------|-------\n");
    
    int top_display = (result_count < 10) ? result_count : 10;
    for (int i = 0; i < top_display; i++) {
        printf("%4d | %-36s | %7.1f%% | %8.1f%% | %5.1f%% | %7.1f%% | %6.1f%% | %5.0f%%\n", 
               i + 1, 
               results[i].full_name,
               results[i].avg_accuracy * 100,
               results[i].avg_precision * 100,
               results[i].avg_recall * 100,
               results[i].avg_f1_score * 100,
               results[i].avg_auc_roc * 100,
               results[i].convergence_rate * 100);
    }
    
    // Statistiques par m√©thode neuroplast
    printf("\nüìä PERFORMANCES MOYENNES PAR M√âTHODE NEUROPLAST :\n");
    for (int m = 0; m < num_methods; m++) {
        float total_score = 0.0f;
        int count = 0;
        
        for (int i = 0; i < result_count; i++) {
            if (strcmp(results[i].method, neuroplast_methods[m]) == 0) {
                total_score += results[i].avg_f1_score;
                count++;
            }
        }
        
        if (count > 0) {
            printf("   %-12s : %.1f%% (sur %d combinaisons)\n", 
                   neuroplast_methods[m], (total_score / count) * 100, count);
        }
    }
    
    // Statistiques par optimiseur
    printf("\n‚ö° PERFORMANCES MOYENNES PAR OPTIMISEUR :\n");
    for (int o = 0; o < num_optimizers; o++) {
        float total_score = 0.0f;
        int count = 0;
        
        for (int i = 0; i < result_count; i++) {
            if (strcmp(results[i].optimizer, optimizers[o]) == 0) {
                total_score += results[i].avg_f1_score;
                count++;
            }
        }
        
        if (count > 0) {
            printf("   %-12s : %.1f%% (sur %d combinaisons)\n", 
                   optimizers[o], (total_score / count) * 100, count);
        }
    }
    
    // Statistiques par activation
    printf("\nüéØ PERFORMANCES MOYENNES PAR ACTIVATION :\n");
    for (int a = 0; a < num_activations; a++) {
        float total_score = 0.0f;
        int count = 0;
        
        for (int i = 0; i < result_count; i++) {
            if (strcmp(results[i].activation, activations[a]) == 0) {
                total_score += results[i].avg_f1_score;
                count++;
            }
        }
        
        if (count > 0) {
            printf("   %-12s : %.1f%% (sur %d combinaisons)\n", 
                   activations[a], (total_score / count) * 100, count);
        }
    }
    
    // Combinaisons avec convergence excellente
    printf("\n‚úÖ COMBINAISONS AVEC CONVERGENCE EXCELLENTE (>80%% F1) :\n");
    int excellent_count = 0;
    for (int i = 0; i < result_count; i++) {
        if (results[i].convergence_rate >= 0.5f && results[i].avg_f1_score >= 0.8f) {
            printf("   %s (%.1f%% avg F1)\n", results[i].full_name, results[i].avg_f1_score * 100);
            excellent_count++;
        }
    }
    if (excellent_count == 0) {
        printf("   Aucune combinaison avec convergence excellente trouv√©e.\n");
    }
    
    // Recommandations finales
    printf("\nüéä RECOMMANDATIONS FINALES (DATASET R√âEL) :\n");
    printf("‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n");
    if (result_count > 0) {
        printf("ü•á Meilleure combinaison : %s\n", results[0].full_name);
        printf("\nüìä M√âTRIQUES MOYENNES :\n");
        printf("   üéØ Accuracy    : %.1f%%\n", results[0].avg_accuracy * 100);
        printf("   üîç Precision   : %.1f%%\n", results[0].avg_precision * 100);
        printf("   üìà Recall      : %.1f%%\n", results[0].avg_recall * 100);
        printf("   üèÜ F1-Score    : %.1f%%\n", results[0].avg_f1_score * 100);
        printf("   üìà AUC-ROC     : %.1f%%\n", results[0].avg_auc_roc * 100);
        printf("\nüìä MEILLEURES M√âTRIQUES OBTENUES :\n");
        printf("   üåü Best Accuracy  : %.1f%%\n", results[0].best_accuracy * 100);
        printf("   üåü Best Precision : %.1f%%\n", results[0].best_precision * 100);
        printf("   üåü Best Recall    : %.1f%%\n", results[0].best_recall * 100);
        printf("   üåü Best F1-Score  : %.1f%%\n", results[0].best_f1_score * 100);
        printf("   üåü Best AUC-ROC   : %.1f%%\n", results[0].best_auc_roc * 100);
        printf("\n‚úÖ Taux de convergence : %.0f%% (%d/%d essais)\n", 
               results[0].convergence_rate * 100, results[0].convergence_count, results[0].total_trials);
        printf("üéØ Architecture test√©e : Input(%zu)‚Üí256‚Üí128‚ÜíOutput(%zu)\n", dataset->input_cols, dataset->output_cols);
        printf("üìà Total combinaisons test√©es : %d sur %d possibles\n", result_count, total_combinations);
        printf("üìä Dataset utilis√© : %s (%zu √©chantillons)\n", config_path, dataset->num_samples);
        printf("‚è±Ô∏è Test exhaustif √©quivalent √† la commande compl√®te !\n");
    }
    
    // Finaliser les barres de progression
    progress_global_finish(general_bar);
    progress_global_finish(trials_bar);
    progress_global_finish(epochs_bar);
    
    // D√©sactiver le mode progression s√©curis√© pour les messages finaux
    colored_output_set_progress_mode(0);
    
    // Sauvegarder les informations du dataset avant lib√©ration (IMPORTANT!)
    size_t dataset_num_samples = dataset->num_samples;
    size_t dataset_input_cols = dataset->input_cols;
    size_t dataset_output_cols = dataset->output_cols;
    
    // EXPORT CSV COMPLET AVEC TOUTES LES M√âTRIQUES - AVANT NETTOYAGE
    printf("\nüìä EXPORT DES R√âSULTATS EN CSV AVEC TOUTES LES M√âTRIQUES...\n");
    
    // Tri des r√©sultats par F1-Score moyen (meilleur en premier)
    for (int i = 0; i < result_count - 1; i++) {
        for (int j = 0; j < result_count - i - 1; j++) {
            if (results[j].avg_f1_score < results[j + 1].avg_f1_score) {
                CombinationResult temp = results[j];
                results[j] = results[j + 1];
                results[j + 1] = temp;
            }
        }
    }
    
    char csv_filename[256];
    time_t now = time(NULL);
    struct tm *tm_info = localtime(&now);
    strftime(csv_filename, sizeof(csv_filename), "results_exhaustif_xor_simulatedMedical_%Y%m%d_%H%M%S.csv", tm_info);
    
    FILE *csv_file = fopen(csv_filename, "w");
    if (csv_file) {
        // En-t√™te CSV avec m√©tadonn√©es compl√®tes
        fprintf(csv_file, "# NEUROPLAST-ANN - Test Exhaustif XOR M√©dical Simul√©\n");
        fprintf(csv_file, "# Dataset: M√©dical simul√© (%zu √©chantillons, %zu features)\n", dataset_num_samples, dataset_input_cols);
        fprintf(csv_file, "# Architecture: Input(%zu)‚Üí256‚Üí128‚ÜíOutput(%zu)\n", dataset_input_cols, dataset_output_cols);
        fprintf(csv_file, "# Total combinaisons: %d\n", total_combinations);
        fprintf(csv_file, "# Essais par combinaison: 5\n");
        fprintf(csv_file, "# √âpoques max: 50\n");
        fprintf(csv_file, "# Features m√©dicales: Age, Cholest√©rol, Tension, BMI, Exercice, Tabac, Ant√©c√©dents, Stress\n");
        fprintf(csv_file, "# Mod√®le de risque: Interactions complexes + bruit r√©aliste\n");
        fprintf(csv_file, "# Toutes les m√©triques: Accuracy, Precision, Recall, F1-Score, AUC-ROC\n");
        fprintf(csv_file, "#\n");
        
        // En-t√™te des colonnes CSV
        fprintf(csv_file, "Rang,Methode,Optimiseur,Activation,Combinaison_Complete,");
        fprintf(csv_file, "Avg_Accuracy_Pct,Avg_Precision_Pct,Avg_Recall_Pct,Avg_F1_Score_Pct,Avg_AUC_ROC_Pct,");
        fprintf(csv_file, "Best_Accuracy_Pct,Best_Precision_Pct,Best_Recall_Pct,Best_F1_Score_Pct,Best_AUC_ROC_Pct,");
        fprintf(csv_file, "Convergence_Count,Total_Trials,Taux_Convergence_Pct\n");
        
        // Donn√©es tri√©es avec toutes les m√©triques
        for (int i = 0; i < result_count; i++) {
            fprintf(csv_file, "%d,%s,%s,%s,%s,",
                   i + 1,
                   results[i].method,
                   results[i].optimizer,
                   results[i].activation,
                   results[i].full_name);
            
            // M√©triques moyennes (en pourcentage)
            fprintf(csv_file, "%.2f,%.2f,%.2f,%.2f,%.2f,",
                   results[i].avg_accuracy * 100,
                   results[i].avg_precision * 100,
                   results[i].avg_recall * 100,
                   results[i].avg_f1_score * 100,
                   results[i].avg_auc_roc * 100);
            
            // Meilleures m√©triques (en pourcentage)
            fprintf(csv_file, "%.2f,%.2f,%.2f,%.2f,%.2f,",
                   results[i].best_accuracy * 100,
                   results[i].best_precision * 100,
                   results[i].best_recall * 100,
                   results[i].best_f1_score * 100,
                   results[i].best_auc_roc * 100);
            
            // Informations de convergence
            fprintf(csv_file, "%d,%d,%.2f\n",
                   results[i].convergence_count,
                   results[i].total_trials,
                   results[i].convergence_rate);
        }
        
        fclose(csv_file);
        
        printf("‚úÖ R√©sultats export√©s vers : %s\n", csv_filename);
        printf("üìä %d combinaisons sauvegard√©es avec TOUTES les m√©triques\n", result_count);
        printf("üè• M√©triques incluses : Accuracy, Precision, Recall, F1-Score, AUC-ROC\n");
        printf("üìà Donn√©es tri√©es par F1-Score moyen d√©croissant\n");
        
        // Affichage du TOP 5 pour v√©rification
        printf("\nüèÜ TOP 5 DES MEILLEURES COMBINAISONS (TOUTES M√âTRIQUES) :\n");
        printf("‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n");
        printf("Rang | Combinaison                          | Accuracy | Precision | Recall | F1-Score | AUC-ROC | Conv\n");
        printf("-----|--------------------------------------|----------|-----------|--------|----------|---------|-----\n");
        int top_display = (result_count < 5) ? result_count : 5;
        for (int i = 0; i < top_display; i++) {
            printf("%4d | %-36s | %7.1f%% | %8.1f%% | %5.1f%% | %7.1f%% | %6.1f%% | %3.0f%%\n", 
                   i + 1, 
                   results[i].full_name,
                   results[i].avg_accuracy * 100,
                   results[i].avg_precision * 100,
                   results[i].avg_recall * 100,
                   results[i].avg_f1_score * 100,
                   results[i].avg_auc_roc * 100,
                   results[i].convergence_rate * 100);
        }
        
    } else {
        printf("‚ùå Erreur lors de la cr√©ation du fichier CSV : %s\n", csv_filename);
    }
    
    // Lib√©ration m√©moire des r√©sultats APR√àS l'export CSV
    free(results);

    // üéØ FINALISER LA SAUVEGARDE DES 10 MEILLEURS MOD√àLES
    printf("\nüíæ FINALISATION DE LA SAUVEGARDE DES 10 MEILLEURS MOD√àLES\n");
    printf("=========================================================\n");
    int saved_count = finalize_best_models();
    if (saved_count > 0) {
        printf("‚úÖ %d mod√®les dans le top 10 sauvegard√©s avec succ√®s!\n", saved_count);
        printf("üìÅ Dossier: ./best_models_neuroplast/\n");
        printf("üíæ Fichier JSON: best_models_info.json\n");
        printf("üêç Script d'analyse: analyze_best_models.py\n");
    } else {
        printf("‚ö†Ô∏è Aucun mod√®le sauvegard√© (gestionnaire non initialis√©)\n");
    }

    // Nettoyage final
    dataset_free(dataset);
    dataset_free(train_set);
    dataset_free(test_set);
    
    // Nettoyer le syst√®me de sauvegarde
    cleanup_best_models();
    
    // Nettoyer le syst√®me de progression
    progress_global_cleanup();
    
    return 0;
}

// Test complet de tous les ensembles avec comparaison (dataset r√©aliste avec toutes les m√©triques)
int test_all(const RichConfig *cfg) {
    printf("üöÄ TEST EXHAUSTIF DE TOUTES LES COMBINAISONS\n");
    printf("===========================================\n\n");
    
    // V√©rifier si l'optimisation adaptative est activ√©e
    if (cfg->optimized_parameters) {
        printf("üöÄ MODE OPTIMISATION ADAPTATIVE TEMPS R√âEL ACTIV√â!\n");
        printf("===================================================\n\n");
        
        printf("üéØ OBJECTIF: Atteindre 90%%+ d'accuracy via adaptation dynamique\n");
        printf("‚ö° STRAT√âGIE: Optimiseur temps r√©el int√©gr√©\n");
        printf("üîÑ CYCLES: Adaptation automatique des param√®tres\n");
        printf("üìä CONFIGURATION: G√©n√©ration dynamique des configurations\n\n");
        
        // Lancer l'optimiseur adaptatif int√©gr√©
        // Note: On utilise une configuration de base (on pourrait la d√©duire du cfg)
        char base_config_path[512];
        snprintf(base_config_path, sizeof(base_config_path), "config/test_convergence.yml");
        
        printf("üìÅ Configuration de base utilis√©e: %s\n", base_config_path);
        printf("üîß Param√®tres adaptatifs bas√©s sur la configuration actuelle\n\n");
        
        return run_adaptive_optimization(cfg, base_config_path);
    }
    
    // Mode configuration statique (comportement original)
    printf("üìä MODE CONFIGURATION STATIQUE\n");
    printf("===============================\n\n");
    
    // D√©finir toutes les combinaisons comme dans la commande compl√®te
    const char *neuroplast_methods[] = {"standard", "adaptive", "advanced", "bayesian", "progressive", "swarm", "propagation"};
    const char *optimizers[] = {"adamw", "adam", "sgd", "rmsprop", "lion", "adabelief", "radam", "adamax", "nadam"};
    const char *activations[] = {"neuroplast", "relu", "leaky_relu", "gelu", "sigmoid", "elu", "mish", "swish", "prelu"};
    
    int num_methods = 7;
    int num_optimizers = 9;
    int num_activations = 9;
    int total_combinations = num_methods * num_optimizers * num_activations;
    
    printf("üéØ CONFIGURATION UTILIS√âE :\n");
    printf("   üìä %d m√©thodes neuroplast\n", num_methods);
    printf("   ‚ö° %d optimiseurs\n", num_optimizers); 
    printf("   üéØ %d fonctions d'activation\n", num_activations);
    printf("   üöÄ %d combinaisons TOTALES\n", total_combinations);
    printf("   üîÑ 5 essais par combinaison\n");
    printf("   üìà %d √©poques max par essai\n", cfg->max_epochs);
    printf("   ‚è∞ Early stopping: %s (patience: %d)\n\n", 
           cfg->early_stopping ? "‚úÖ Activ√©" : "‚ùå D√©sactiv√©", cfg->patience);
    
    printf("‚è±Ô∏è Dur√©e estim√©e : 30-45 minutes (mode exhaustif)\n");
    printf("üìä Architecture : Input(8)‚Üí256‚Üí128‚ÜíOutput(1)\n");
    printf("üéØ Dataset : M√©dical simul√© (800 √©chantillons)\n\n");
    
    // Appeler la fonction de test existante avec les param√®tres appropri√©s
    // Utiliser le fichier de configuration pass√© en param√®tre s'il existe
    const char *config_file = "config/test_convergence.yml"; // Valeur par d√©faut
    
    // Parcourir les arguments pour trouver --config
    for (int i = 1; i < argc_global - 1; i++) {
        if (strcmp(argv_global[i], "--config") == 0) {
            config_file = argv_global[i + 1];
            printf("üìÅ Utilisation du fichier de configuration: %s\n", config_file);
            break;
        }
    }
    
    if (strcmp(config_file, "config/test_convergence.yml") == 0) {
        printf("üìÅ Utilisation de la configuration par d√©faut: %s\n", config_file);
    }
    
    return test_all_with_real_dataset(neuroplast_methods, num_methods,
                                     optimizers, num_optimizers,
                                     activations, num_activations,
                                     config_file, 150); // AUGMENTER LES √âPOQUES DE 100 √Ä 150
}

// Fonction main pour g√©rer les modes de test
int main(int argc, char *argv[]) {
    // Sauvegarder les arguments globalement
    argc_global = argc;
    argv_global = argv;
    
    // Initialiser le g√©n√©rateur de nombres al√©atoires
    srand(time(NULL));
    
    print_banner();
    
    // Initialiser la configuration par d√©faut
    RichConfig cfg;
    memset(&cfg, 0, sizeof(RichConfig));
    
    // Valeurs par d√©faut
    cfg.batch_size = 32;
    cfg.max_epochs = 100;
    cfg.learning_rate = 0.001f;
    cfg.early_stopping = 1;  // Activ√© par d√©faut
    cfg.patience = 20;       // Patience par d√©faut
    cfg.input_cols = 8;      // Pour le dataset m√©dical simul√©
    cfg.output_cols = 1;     // Classification binaire
    
    // Essayer de charger une configuration si un fichier est fourni
    int config_found = 0;
    for (int i = 1; i < argc - 1; i++) {
        if (strcmp(argv[i], "--config") == 0) {
            if (parse_yaml_rich_config(argv[i + 1], &cfg)) {
                printf("‚úÖ Configuration charg√©e depuis : %s\n", argv[i + 1]);
                config_found = 1;
            } else {
                printf("‚ö†Ô∏è Impossible de charger la configuration : %s\n", argv[i + 1]);
                printf("üìù Utilisation de la configuration par d√©faut\n");
            }
            break;
        }
    }
    
    if (!config_found) {
        printf("üìù Aucun fichier de configuration fourni, utilisation des valeurs par d√©faut\n");
    }
    
    // Afficher la configuration utilis√©e
    printf("\nüîß CONFIGURATION UTILIS√âE :\n");
    print_rich_config(&cfg);
    printf("\n");
    
    // V√©rifier si c'est un mode de test
    RunMode mode = get_run_mode(argc, argv);
    
    if (mode != MODE_DEFAULT) {
        printf("üß™ MODE TEST ACTIV√â\n\n");
        
        switch (mode) {
            case MODE_TEST_HEART_DISEASE:
                printf("ü´Ä Test sp√©cialis√© Heart Disease\n");
                // TODO: Impl√©menter le test heart disease
                break;
            case MODE_TEST_ENHANCED:
                printf("‚ö° Test Enhanced Network\n");
                // TODO: Impl√©menter le test enhanced
                break;
            case MODE_TEST_ROBUST:
                printf("üõ°Ô∏è Test Robust Network\n");
                // TODO: Impl√©menter le test robust
                break;
            case MODE_TEST_OPTIMIZED_METRICS:
                printf("üìä Test Optimized Metrics\n");
                // TODO: Impl√©menter le test optimized metrics
                break;
            case MODE_TEST_ALL_ACTIVATIONS:
                return test_all_activations();
            case MODE_TEST_ALL_OPTIMIZERS:
                return test_all_optimizers();
            case MODE_TEST_NEUROPLAST_METHODS:
                return test_neuroplast_methods();
            case MODE_TEST_COMPLETE_COMBINATIONS:
                return test_complete_combinations();
            case MODE_TEST_ALL:
                return test_all(&cfg);
            default:
                break;
        }
        
        printf("‚úÖ Test termin√© avec succ√®s\n");
        return EXIT_SUCCESS;
    }

    // Si pas en mode test, afficher un message d'information
    printf("üí° Pour lancer les tests exhaustifs, utilisez : ./neuroplast-ann --test-all\n");
    printf("üìä Autres modes disponibles :\n");
    printf("   --test-all-activations\n");
    printf("   --test-all-optimizers\n");
    printf("   --test-neuroplast-methods\n");
    printf("   --test-complete-combinations\n");
    printf("   --test-benchmark-full\n\n");
    
    printf("üîß Pour utiliser une configuration personnalis√©e :\n");
    printf("   ./neuroplast-ann --config config/example_early_stopping_enabled.yml --test-all\n");
    printf("   ./neuroplast-ann --config config/example_early_stopping_disabled.yml --test-all\n\n");
    
    return EXIT_SUCCESS;
}


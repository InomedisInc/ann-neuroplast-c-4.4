# Configuration ADAPTATIVE TEMPS R√âEL - It√©ration 5
# ===================================================
# G√©n√©r√©e automatiquement par l'optimiseur temps r√©el int√©gr√©

# Configuration ULTRA-OPTIMIS√âE pour 90%+ d'accuracy
# ==================================================
# Param√®tres ultra-agressifs pour d√©passer 90%

# Param√®tres d'entra√Ænement ULTRA-OPTIMIS√âS pour 90%+
max_epochs: 50           # √âpoques par cycle d'adaptation
early_stopping: true     # Early stopping pour √©viter overfitting
patience: 15             # Patience pour ce cycle
batch_size: 4           # Batch size adaptatif
learning_rate: 0.00000250     # Learning rate adaptatif

# Optimisation adaptative temps r√©el
optimized_parameters: true  # Active l'optimiseur temps r√©el int√©gr√©

# R√©gularisation ultra-optimis√©e
dropout_rate: 0.000       # Dropout adaptatif
l2_regularization: 0.0   # Aucune L2 pour expressivit√© maximale

# Momentum ultra-optimal
momentum: 0.950           # Momentum adaptatif

# Gestion des classes ULTRA-optimis√©e pour 90%+
class_weights: [1.0, 5.0]  # Ratio adaptatif

# M√©thodes neuroplast ultra-optimis√©es (focus sur les plus performantes)
neuroplast_methods:
  - neuroplast           # M√©thode sp√©cialis√©e la plus performante UNIQUEMENT
  - adaptive             # M√©thode adaptative

# Optimiseurs ultra-optimis√©s (focus sur le meilleur)
optimizers:
  - adamw               # AdamW UNIQUEMENT - le meilleur selon nos tests

# Activations ultra-optimis√©es (focus sur les meilleures)
activations:
  - neuroplast          # Activation sp√©cialis√©e UNIQUEMENT
  - gelu                # GELU comme backup

# M√©triques compl√®tes
metrics:
  - accuracy
  - f1_score
  - precision
  - recall

# Commentaires d'optimisation ultra-agressive
# ============================================
# CHANGEMENTS POUR 90%+:
max_epochs: 50           # √âpoques par cycle d'adaptation
batch_size: 4           # Batch size adaptatif
learning_rate: 0.00000250     # Learning rate adaptatif
patience: 15             # Patience pour ce cycle
momentum: 0.950           # Momentum adaptatif
class_weights: [1.0, 5.0]  # Ratio adaptatif
# - optimized_parameters: true (NOUVEAU - optimiseur temps r√©el)
# - R√©duction des options pour focus sur les meilleures
# 
# STRAT√âGIE ULTRA-AGRESSIVE:
# 1. Fine-tuning extr√™me avec LR minimal
# 2. Gradients ultra-pr√©cis avec batch=1
# 3. Convergence ultra-stable avec momentum=0.99
# 4. Compensation maximale du d√©s√©quilibre (5:1)
# 5. Patience maximale pour convergence compl√®te
# 6. Focus uniquement sur les m√©thodes les plus performantes
# 7. OPTIMISEUR TEMPS R√âEL pour adaptation dynamique automatique 
# √âtat de l'adaptation temps r√©el
adaptation_state: |
  üîÑ ADAPTATION TEMPS R√âEL 5:
  
  üìä PERFORMANCE ACTUELLE:
  - Accuracy courante: 0.00%
  - Meilleure accuracy: 0.00%
  - Objectif: 90%
  
  üîß PARAM√àTRES ADAPTATIFS:
  - Learning Rate: 0.00000250
  - Momentum: 0.950
  - Dropout: 0.000
  - Class Weight Ratio: 5.0
  - Batch Size: 4
  
  üìà √âTAT D'ADAPTATION:
  - √âpoques totales: 200
  - Stagnation: 4 √©poques
  - Am√©liorations: 0 √©poques
  - Adaptations effectu√©es: 0

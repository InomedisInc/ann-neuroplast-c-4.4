# Configuration ADAPTATIVE pour Cancer du sein
# Optimisation dynamique en temps rÃ©el des paramÃ¨tres

dataset: "datasets/Cancer.csv"
input_cols: 30    # 30 features cancer
output_cols: 1    # Classification binaire M/B

# PARAMÃˆTRES INITIAUX (seront ajustÃ©s dynamiquement)
batch_size: 32
max_epochs: 200
learning_rate: 0.001      # Point de dÃ©part - sera adaptÃ©
momentum: 0.9             # Point de dÃ©part - sera adaptÃ©
dropout_rate: 0.1         # Point de dÃ©part - sera adaptÃ©
l2_regularization: 0.0001 # Point de dÃ©part - sera adaptÃ©

# Gestion des classes (sera adaptÃ©e dynamiquement)
class_weights: [1.0, 1.5]  # Ratio initial - sera optimisÃ©

# Configuration de l'optimisation adaptative
adaptive_optimization:
  enabled: true
  adaptation_frequency: 5        # Adapter tous les 5 epochs
  
  # StratÃ©gies d'adaptation activÃ©es
  adapt_learning_rate: true
  adapt_momentum: true
  adapt_dropout: true
  adapt_class_weights: true
  adapt_l2_regularization: false  # Garder L2 fixe pour simplicitÃ©
  
  # Limites d'adaptation intelligentes
  learning_rate_bounds: [0.00001, 0.01]    # 1% Ã  1000% du LR initial
  momentum_bounds: [0.5, 0.999]            # Range momentum
  dropout_bounds: [0.0, 0.5]               # 0% Ã  50% dropout
  class_weight_bounds: [0.5, 10.0]         # Ratio de 0.5 Ã  10
  
  # Seuils de dÃ©clenchement
  stagnation_threshold: 10      # Epochs sans amÃ©lioration avant adaptation
  improvement_threshold: 0.05   # 5% d'amÃ©lioration pour augmenter LR
  overfitting_threshold: 0.1    # 10% gap train/val pour augmenter dropout
  oscillation_threshold: 0.02   # 2% volatility pour rÃ©duire momentum
  
  # Facteurs d'ajustement
  lr_reduction_factor: 0.8      # RÃ©duire LR de 20% si stagnation
  lr_increase_factor: 1.1       # Augmenter LR de 10% si amÃ©lioration rapide
  momentum_adjustment: 0.02     # Ajustement momentum Â±2%
  dropout_adjustment: 0.05      # Ajustement dropout Â±5%
  class_weight_adjustment: 0.2  # Ajustement poids classes Â±20%

# Analyse automatique du dataset
dataset_analysis:
  auto_detect_type: true        # DÃ©tecter automatiquement le type
  analyze_class_distribution: true
  calculate_feature_variance: true
  estimate_complexity: true
  
  # Actions basÃ©es sur l'analyse
  auto_adjust_initial_params: true
  complexity_based_adaptation: true

# Early stopping adaptatif
early_stopping: true
patience: 30                    # Plus de patience pour adaptation
min_delta: 0.001               # AmÃ©lioration minimale requise

# Monitoring et export
metrics_export: true
csv_export: true
save_adaptation_history: true   # Sauvegarder l'historique des adaptations
verbose_adaptation: true        # Afficher les adaptations en temps rÃ©el

# Validation croisÃ©e adaptative (optionnel)
adaptive_validation:
  enabled: false               # DÃ©sactivÃ© par dÃ©faut
  cv_folds: 5
  adapt_based_on_cv: false

name: "cancer_adaptive_realtime"
description: "Configuration adaptative temps rÃ©el - optimisation automatique"

# Instructions d'utilisation
usage_instructions: |
  OPTIMISATION ADAPTATIVE EN TEMPS RÃ‰EL:
  
  Cette configuration dÃ©marre avec des paramÃ¨tres initiaux raisonnables
  puis les ajuste automatiquement pendant l'entraÃ®nement basÃ© sur:
  
  ğŸ“Š ANALYSE AUTOMATIQUE DU DATASET:
  - DÃ©tection du type (binaire/multi-classe)
  - Distribution des classes
  - Variance des features
  - Estimation de la complexitÃ©
  
  ğŸ”„ ADAPTATION DYNAMIQUE:
  - Learning Rate: RÃ©duit si stagnation, augmente si amÃ©lioration rapide
  - Momentum: Augmente si convergence lente, rÃ©duit si oscillations
  - Dropout: Augmente si overfitting, rÃ©duit si underfitting
  - Class Weights: Ajuste basÃ© sur performance par classe
  
  âš¡ DÃ‰CLENCHEURS INTELLIGENTS:
  - Stagnation > 10 epochs â†’ RÃ©duction LR
  - AmÃ©lioration > 5% â†’ Augmentation LR
  - Gap train/val > 10% â†’ Augmentation dropout
  - Volatility > 2% â†’ RÃ©duction momentum
  
  ğŸ¯ COMMANDES:
  ./neuroplast-ann --config config/adaptive_cancer.yml
  ./neuroplast-ann --config config/adaptive_cancer.yml --test-all-optimizers

# StratÃ©gie d'adaptation dÃ©taillÃ©e
adaptation_strategy: |
  STRATÃ‰GIE D'OPTIMISATION ADAPTATIVE:
  
  1. PHASE D'INITIALISATION:
     âœ… Analyse automatique du dataset
     âœ… Ajustement des paramÃ¨tres initiaux basÃ© sur la complexitÃ©
     âœ… DÃ©finition des limites d'adaptation intelligentes
  
  2. PHASE D'ENTRAÃNEMENT ADAPTATIF:
     ğŸ”„ Monitoring continu des mÃ©triques
     ğŸ“Š Historique des performances (100 derniers epochs)
     ğŸ¯ DÃ©tection automatique des patterns (stagnation, oscillations, overfitting)
     âš¡ Adaptation en temps rÃ©el tous les 5 epochs
  
  3. STRATÃ‰GIES D'ADAPTATION:
     
     ğŸ“‰ LEARNING RATE:
     - Stagnation dÃ©tectÃ©e â†’ RÃ©duction 20%
     - AmÃ©lioration rapide â†’ Augmentation 10%
     - Loss en hausse â†’ RÃ©duction 10%
     
     ğŸš€ MOMENTUM:
     - Convergence lente â†’ Augmentation 2%
     - Oscillations dÃ©tectÃ©es â†’ RÃ©duction 5%
     
     ğŸ›¡ï¸ DROPOUT:
     - Overfitting (gap > 10%) â†’ Augmentation 5%
     - Underfitting possible â†’ RÃ©duction 2%
     
     âš–ï¸ CLASS WEIGHTS:
     - Performance dÃ©sÃ©quilibrÃ©e â†’ Ajustement 20%
     - Classe critique sous-performante â†’ Augmentation poids
  
  4. LIMITES DE SÃ‰CURITÃ‰:
     ğŸ”’ LR: 0.00001 - 0.01 (1% Ã  1000% initial)
     ğŸ”’ Momentum: 0.5 - 0.999
     ğŸ”’ Dropout: 0.0 - 0.5
     ğŸ”’ Class Weights: 0.5 - 10.0
  
  RÃ‰SULTAT: Optimisation automatique pour n'importe quel dataset! 
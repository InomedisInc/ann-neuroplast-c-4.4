# Configuration UNIVERSELLE ADAPTATIVE
# S'adapte automatiquement Ã  n'importe quel dataset

# DATASET FLEXIBLE (sera analysÃ© automatiquement)
dataset: "auto_detect"        # DÃ©tection automatique du dataset
input_cols: "auto"           # DÃ©tection automatique du nombre de features
output_cols: "auto"          # DÃ©tection automatique du nombre de classes

# PARAMÃˆTRES INITIAUX UNIVERSELS (optimisÃ©s pour la plupart des cas)
batch_size: 32               # Bon compromis pour la plupart des datasets
max_epochs: 300              # Suffisant pour convergence avec early stopping
learning_rate: 0.001         # Point de dÃ©part standard
momentum: 0.9                # Point de dÃ©part standard
dropout_rate: 0.1            # LÃ©gÃ¨re rÃ©gularisation initiale
l2_regularization: 0.0001    # RÃ©gularisation minimale

# GESTION ADAPTATIVE DES CLASSES
class_weights: "auto_balance"  # Calcul automatique basÃ© sur distribution

# OPTIMISATION ADAPTATIVE AVANCÃ‰E
adaptive_optimization:
  enabled: true
  adaptation_frequency: 3      # Adaptation plus frÃ©quente (tous les 3 epochs)
  
  # TOUTES LES ADAPTATIONS ACTIVÃ‰ES
  adapt_learning_rate: true
  adapt_momentum: true
  adapt_dropout: true
  adapt_class_weights: true
  adapt_batch_size: false      # Garder batch size fixe pour stabilitÃ©
  adapt_architecture: false   # Garder architecture fixe
  
  # LIMITES D'ADAPTATION INTELLIGENTES (basÃ©es sur dataset)
  learning_rate_bounds: "auto"    # CalculÃ©es automatiquement
  momentum_bounds: [0.5, 0.999]
  dropout_bounds: [0.0, 0.6]     # Plus large pour datasets complexes
  class_weight_bounds: [0.1, 20.0]  # Large range pour dÃ©sÃ©quilibres extrÃªmes
  
  # SEUILS ADAPTATIFS (ajustÃ©s selon complexitÃ© dataset)
  stagnation_threshold: "auto"     # CalculÃ© selon taille dataset
  improvement_threshold: 0.03     # 3% d'amÃ©lioration (plus sensible)
  overfitting_threshold: 0.08     # 8% gap train/val
  oscillation_threshold: 0.015    # 1.5% volatility
  
  # FACTEURS D'AJUSTEMENT INTELLIGENTS
  lr_reduction_factor: 0.75       # RÃ©duction plus douce
  lr_increase_factor: 1.15        # Augmentation plus agressive
  momentum_adjustment: 0.03       # Ajustement momentum Â±3%
  dropout_adjustment: 0.03        # Ajustement dropout Â±3%
  class_weight_adjustment: 0.25   # Ajustement poids classes Â±25%

# ANALYSE AUTOMATIQUE COMPLÃˆTE DU DATASET
dataset_analysis:
  auto_detect_type: true          # Classification binaire/multi-classe/rÃ©gression
  analyze_class_distribution: true
  calculate_feature_variance: true
  estimate_complexity: true
  detect_outliers: true
  analyze_feature_correlations: true
  
  # ACTIONS AUTOMATIQUES BASÃ‰ES SUR L'ANALYSE
  auto_adjust_initial_params: true
  complexity_based_adaptation: true
  imbalance_based_weights: true
  outlier_based_regularization: true

# STRATÃ‰GIES SPÃ‰CIALISÃ‰ES PAR TYPE DE DATASET
dataset_specific_strategies:
  binary_classification:
    focus_metric: "f1_score"
    class_weight_strategy: "inverse_frequency"
    threshold_optimization: true
    
  multi_class:
    focus_metric: "accuracy"
    class_weight_strategy: "balanced"
    one_vs_rest_adaptation: true
    
  imbalanced_dataset:
    aggressive_class_weighting: true
    focal_loss_adaptation: true
    minority_class_focus: true
    
  small_dataset:
    reduce_complexity: true
    increase_regularization: true
    cross_validation: true
    
  large_dataset:
    increase_batch_size: true
    reduce_regularization: true
    faster_convergence: true

# EARLY STOPPING ADAPTATIF INTELLIGENT
early_stopping: true
patience: "auto"                 # CalculÃ©e selon taille dataset
min_delta: "auto"               # CalculÃ©e selon variance des mÃ©triques
restore_best_weights: true

# MONITORING ET EXPORT COMPLETS
metrics_export: true
csv_export: true
save_adaptation_history: true
verbose_adaptation: true
plot_training_curves: true
save_best_model: true

# VALIDATION ADAPTATIVE
adaptive_validation:
  enabled: true
  strategy: "auto"              # Holdout, CV, ou stratified selon dataset
  cv_folds: "auto"             # CalculÃ© selon taille dataset
  stratified: true             # Pour datasets dÃ©sÃ©quilibrÃ©s

name: "universal_adaptive_optimizer"
description: "Configuration universelle - s'adapte Ã  n'importe quel dataset automatiquement"

# INSTRUCTIONS D'UTILISATION UNIVERSELLE
usage_instructions: |
  ğŸŒ OPTIMISEUR UNIVERSEL ADAPTATIF:
  
  Cette configuration s'adapte automatiquement Ã  N'IMPORTE QUEL dataset:
  
  ğŸ“Š ANALYSE AUTOMATIQUE COMPLÃˆTE:
  - Type de problÃ¨me (classification/rÃ©gression)
  - Nombre de classes/features
  - Distribution et dÃ©sÃ©quilibre des classes
  - ComplexitÃ© et variance des donnÃ©es
  - DÃ©tection d'outliers et corrÃ©lations
  
  ğŸ”„ ADAPTATION INTELLIGENTE:
  - ParamÃ¨tres initiaux ajustÃ©s selon l'analyse
  - Adaptation en temps rÃ©el pendant l'entraÃ®nement
  - StratÃ©gies spÃ©cialisÃ©es par type de dataset
  - Limites d'adaptation calculÃ©es automatiquement
  
  ğŸ¯ UTILISATION SIMPLE:
  1. Placez votre dataset dans datasets/
  2. Lancez: ./neuroplast-ann --config config/universal_adaptive.yml
  3. Le systÃ¨me fait tout automatiquement !
  
  âœ¨ DATASETS SUPPORTÃ‰S:
  - Cancer, Heart Disease, Diabetes, Iris, Wine, etc.
  - Binaire, multi-classe, Ã©quilibrÃ©, dÃ©sÃ©quilibrÃ©
  - Petit (100 Ã©chantillons) Ã  grand (100k+ Ã©chantillons)
  - Toute complexitÃ© de features

# STRATÃ‰GIES D'ADAPTATION UNIVERSELLES
universal_strategies: |
  ğŸ§  INTELLIGENCE ADAPTATIVE UNIVERSELLE:
  
  1. PHASE D'ANALYSE AUTOMATIQUE:
     ğŸ” DÃ©tection du type de dataset
     ğŸ“Š Analyse statistique complÃ¨te
     ğŸ¯ Estimation de la complexitÃ©
     âš–ï¸ Calcul du dÃ©sÃ©quilibre des classes
     ğŸ”— Analyse des corrÃ©lations entre features
  
  2. INITIALISATION INTELLIGENTE:
     ğŸ“ˆ ParamÃ¨tres initiaux optimisÃ©s selon l'analyse
     ğŸšï¸ Limites d'adaptation calculÃ©es dynamiquement
     ğŸ¯ StratÃ©gies spÃ©cialisÃ©es activÃ©es selon le type
     âš¡ FrÃ©quence d'adaptation ajustÃ©e selon la taille
  
  3. ADAPTATION EN TEMPS RÃ‰EL:
     ğŸ“‰ Learning Rate: RÃ©duction si stagnation, augmentation si amÃ©lioration
     ğŸš€ Momentum: Ajustement selon convergence et oscillations
     ğŸ›¡ï¸ Dropout: Adaptation selon overfitting/underfitting
     âš–ï¸ Class Weights: RÃ©Ã©quilibrage selon performance par classe
  
  4. STRATÃ‰GIES SPÃ‰CIALISÃ‰ES:
     ğŸ¯ Binaire: Focus F1-score, optimisation seuil
     ğŸŒˆ Multi-classe: Focus accuracy, stratÃ©gie one-vs-rest
     âš–ï¸ DÃ©sÃ©quilibrÃ©: PondÃ©ration agressive, focal loss
     ğŸ“ Petit dataset: RÃ©gularisation, validation croisÃ©e
     ğŸ“Š Grand dataset: Batch size Ã©levÃ©, convergence rapide
  
  5. VALIDATION ADAPTATIVE:
     âœ… StratÃ©gie de validation selon taille dataset
     ğŸ”„ Cross-validation pour petits datasets
     ğŸ“Š Holdout stratifiÃ© pour grands datasets
     ğŸ¯ MÃ©triques adaptÃ©es au type de problÃ¨me
  
  RÃ‰SULTAT: Optimisation automatique universelle ! ğŸŒŸ 
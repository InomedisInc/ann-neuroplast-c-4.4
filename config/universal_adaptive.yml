# Configuration UNIVERSELLE ADAPTATIVE
# S'adapte automatiquement à n'importe quel dataset

# DATASET FLEXIBLE (sera analysé automatiquement)
dataset: "auto_detect"        # Détection automatique du dataset
input_cols: "auto"           # Détection automatique du nombre de features
output_cols: "auto"          # Détection automatique du nombre de classes

# PARAMÈTRES INITIAUX UNIVERSELS (optimisés pour la plupart des cas)
batch_size: 32               # Bon compromis pour la plupart des datasets
max_epochs: 300              # Suffisant pour convergence avec early stopping
learning_rate: 0.001         # Point de départ standard
momentum: 0.9                # Point de départ standard
dropout_rate: 0.1            # Légère régularisation initiale
l2_regularization: 0.0001    # Régularisation minimale

# GESTION ADAPTATIVE DES CLASSES
class_weights: "auto_balance"  # Calcul automatique basé sur distribution

# OPTIMISATION ADAPTATIVE AVANCÉE
adaptive_optimization:
  enabled: true
  adaptation_frequency: 3      # Adaptation plus fréquente (tous les 3 epochs)
  
  # TOUTES LES ADAPTATIONS ACTIVÉES
  adapt_learning_rate: true
  adapt_momentum: true
  adapt_dropout: true
  adapt_class_weights: true
  adapt_batch_size: false      # Garder batch size fixe pour stabilité
  adapt_architecture: false   # Garder architecture fixe
  
  # LIMITES D'ADAPTATION INTELLIGENTES (basées sur dataset)
  learning_rate_bounds: "auto"    # Calculées automatiquement
  momentum_bounds: [0.5, 0.999]
  dropout_bounds: [0.0, 0.6]     # Plus large pour datasets complexes
  class_weight_bounds: [0.1, 20.0]  # Large range pour déséquilibres extrêmes
  
  # SEUILS ADAPTATIFS (ajustés selon complexité dataset)
  stagnation_threshold: "auto"     # Calculé selon taille dataset
  improvement_threshold: 0.03     # 3% d'amélioration (plus sensible)
  overfitting_threshold: 0.08     # 8% gap train/val
  oscillation_threshold: 0.015    # 1.5% volatility
  
  # FACTEURS D'AJUSTEMENT INTELLIGENTS
  lr_reduction_factor: 0.75       # Réduction plus douce
  lr_increase_factor: 1.15        # Augmentation plus agressive
  momentum_adjustment: 0.03       # Ajustement momentum ±3%
  dropout_adjustment: 0.03        # Ajustement dropout ±3%
  class_weight_adjustment: 0.25   # Ajustement poids classes ±25%

# ANALYSE AUTOMATIQUE COMPLÈTE DU DATASET
dataset_analysis:
  auto_detect_type: true          # Classification binaire/multi-classe/régression
  analyze_class_distribution: true
  calculate_feature_variance: true
  estimate_complexity: true
  detect_outliers: true
  analyze_feature_correlations: true
  
  # ACTIONS AUTOMATIQUES BASÉES SUR L'ANALYSE
  auto_adjust_initial_params: true
  complexity_based_adaptation: true
  imbalance_based_weights: true
  outlier_based_regularization: true

# STRATÉGIES SPÉCIALISÉES PAR TYPE DE DATASET
dataset_specific_strategies:
  binary_classification:
    focus_metric: "f1_score"
    class_weight_strategy: "inverse_frequency"
    threshold_optimization: true
    
  multi_class:
    focus_metric: "accuracy"
    class_weight_strategy: "balanced"
    one_vs_rest_adaptation: true
    
  imbalanced_dataset:
    aggressive_class_weighting: true
    focal_loss_adaptation: true
    minority_class_focus: true
    
  small_dataset:
    reduce_complexity: true
    increase_regularization: true
    cross_validation: true
    
  large_dataset:
    increase_batch_size: true
    reduce_regularization: true
    faster_convergence: true

# EARLY STOPPING ADAPTATIF INTELLIGENT
early_stopping: true
patience: "auto"                 # Calculée selon taille dataset
min_delta: "auto"               # Calculée selon variance des métriques
restore_best_weights: true

# MONITORING ET EXPORT COMPLETS
metrics_export: true
csv_export: true
save_adaptation_history: true
verbose_adaptation: true
plot_training_curves: true
save_best_model: true

# VALIDATION ADAPTATIVE
adaptive_validation:
  enabled: true
  strategy: "auto"              # Holdout, CV, ou stratified selon dataset
  cv_folds: "auto"             # Calculé selon taille dataset
  stratified: true             # Pour datasets déséquilibrés

name: "universal_adaptive_optimizer"
description: "Configuration universelle - s'adapte à n'importe quel dataset automatiquement"

# INSTRUCTIONS D'UTILISATION UNIVERSELLE
usage_instructions: |
  🌍 OPTIMISEUR UNIVERSEL ADAPTATIF:
  
  Cette configuration s'adapte automatiquement à N'IMPORTE QUEL dataset:
  
  📊 ANALYSE AUTOMATIQUE COMPLÈTE:
  - Type de problème (classification/régression)
  - Nombre de classes/features
  - Distribution et déséquilibre des classes
  - Complexité et variance des données
  - Détection d'outliers et corrélations
  
  🔄 ADAPTATION INTELLIGENTE:
  - Paramètres initiaux ajustés selon l'analyse
  - Adaptation en temps réel pendant l'entraînement
  - Stratégies spécialisées par type de dataset
  - Limites d'adaptation calculées automatiquement
  
  🎯 UTILISATION SIMPLE:
  1. Placez votre dataset dans datasets/
  2. Lancez: ./neuroplast-ann --config config/universal_adaptive.yml
  3. Le système fait tout automatiquement !
  
  ✨ DATASETS SUPPORTÉS:
  - Cancer, Heart Disease, Diabetes, Iris, Wine, etc.
  - Binaire, multi-classe, équilibré, déséquilibré
  - Petit (100 échantillons) à grand (100k+ échantillons)
  - Toute complexité de features

# STRATÉGIES D'ADAPTATION UNIVERSELLES
universal_strategies: |
  🧠 INTELLIGENCE ADAPTATIVE UNIVERSELLE:
  
  1. PHASE D'ANALYSE AUTOMATIQUE:
     🔍 Détection du type de dataset
     📊 Analyse statistique complète
     🎯 Estimation de la complexité
     ⚖️ Calcul du déséquilibre des classes
     🔗 Analyse des corrélations entre features
  
  2. INITIALISATION INTELLIGENTE:
     📈 Paramètres initiaux optimisés selon l'analyse
     🎚️ Limites d'adaptation calculées dynamiquement
     🎯 Stratégies spécialisées activées selon le type
     ⚡ Fréquence d'adaptation ajustée selon la taille
  
  3. ADAPTATION EN TEMPS RÉEL:
     📉 Learning Rate: Réduction si stagnation, augmentation si amélioration
     🚀 Momentum: Ajustement selon convergence et oscillations
     🛡️ Dropout: Adaptation selon overfitting/underfitting
     ⚖️ Class Weights: Rééquilibrage selon performance par classe
  
  4. STRATÉGIES SPÉCIALISÉES:
     🎯 Binaire: Focus F1-score, optimisation seuil
     🌈 Multi-classe: Focus accuracy, stratégie one-vs-rest
     ⚖️ Déséquilibré: Pondération agressive, focal loss
     📏 Petit dataset: Régularisation, validation croisée
     📊 Grand dataset: Batch size élevé, convergence rapide
  
  5. VALIDATION ADAPTATIVE:
     ✅ Stratégie de validation selon taille dataset
     🔄 Cross-validation pour petits datasets
     📊 Holdout stratifié pour grands datasets
     🎯 Métriques adaptées au type de problème
  
  RÉSULTAT: Optimisation automatique universelle ! 🌟 
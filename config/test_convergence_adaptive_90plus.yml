# Configuration ADAPTATIVE pour garantir 90%+ d'accuracy
# ======================================================
# Avec optimisation adaptative en temps r√©el

# Param√®tres d'entra√Ænement adaptatifs
max_epochs: 300          # Beaucoup d'√©poques avec early stopping intelligent
early_stopping: true     # Early stopping adaptatif
patience: 50             # Patience √©lev√©e pour adaptation fine
batch_size: 4            # Batch size optimal pour pr√©cision
learning_rate: 0.0001    # Point de d√©part ultra-bas

# Optimisation adaptative activ√©e
adaptive_optimization:
  enabled: true
  adaptation_frequency: 5        # Adapter tous les 5 epochs
  
  # Toutes les adaptations activ√©es
  adapt_learning_rate: true
  adapt_momentum: true
  adapt_dropout: true
  adapt_class_weights: true
  
  # Limites d'adaptation pour haute performance
  learning_rate_bounds: [0.00001, 0.001]    # Range ultra-pr√©cis
  momentum_bounds: [0.85, 0.999]            # Momentum √©lev√©
  dropout_bounds: [0.0, 0.2]                # Dropout minimal
  class_weight_bounds: [1.0, 5.0]           # Pond√©ration adaptative
  
  # Seuils optimis√©s pour 90%+
  stagnation_threshold: 15       # Plus de patience avant adaptation
  improvement_threshold: 0.02    # 2% d'am√©lioration requis
  overfitting_threshold: 0.05    # 5% gap train/val
  oscillation_threshold: 0.01    # 1% volatility
  
  # Facteurs d'ajustement fins
  lr_reduction_factor: 0.8       # R√©duction douce
  lr_increase_factor: 1.1        # Augmentation prudente
  momentum_adjustment: 0.02      # Ajustement fin momentum
  dropout_adjustment: 0.02       # Ajustement fin dropout
  class_weight_adjustment: 0.2   # Ajustement poids classes

# R√©gularisation adaptative
dropout_rate: 0.0        # D√©marrage sans dropout (sera adapt√©)
l2_regularization: 0.0   # Pas de L2 pour expressivit√© maximale

# Gestion des classes optimis√©e
class_weights: [1.0, 2.0]  # Point de d√©part (sera adapt√©)

# M√©thodes neuroplast optimis√©es
neuroplast_methods:
  - neuroplast           # M√©thode sp√©cialis√©e
  - adaptive             # M√©thode adaptative

# Optimiseurs haute performance
optimizers:
  - adamw               # AdamW optimal
  - adam                # Adam backup

# Activations optimis√©es
activations:
  - neuroplast          # Activation sp√©cialis√©e
  - gelu                # GELU performant
  - swish               # Swish pour diversit√©

# Momentum adaptatif
momentum: 0.9            # Point de d√©part (sera adapt√©)

# Architecture optimis√©e
hidden_layers: [128, 64, 32]  # Architecture progressive

# M√©triques compl√®tes
metrics:
  - accuracy
  - f1_score
  - precision
  - recall
  - auc

# Optimisations avanc√©es
use_batch_normalization: true    # Normalisation pour stabilit√©
use_gradient_clipping: true      # Clipping pour stabilit√©
gradient_clip_value: 1.0         # Valeur de clipping

# Strat√©gie d'apprentissage adaptative
learning_rate_schedule: "adaptive"  # Schedule adaptatif
warmup_epochs: 10                   # Warmup pour d√©marrage stable

# Validation stratifi√©e
validation_split: 0.2            # 20% pour validation
stratified_split: true           # Split stratifi√©

# Analyse automatique du dataset
dataset_analysis:
  auto_detect_type: true          # D√©tection automatique
  analyze_class_distribution: true
  calculate_feature_variance: true
  estimate_complexity: true
  
  # Actions automatiques
  auto_adjust_initial_params: true
  complexity_based_adaptation: true
  imbalance_based_weights: true

# Strat√©gies sp√©cialis√©es
dataset_specific_strategies:
  binary_classification:
    focus_metric: "f1_score"
    class_weight_strategy: "inverse_frequency"
    threshold_optimization: true
    
  imbalanced_dataset:
    aggressive_class_weighting: true
    focal_loss_adaptation: true
    minority_class_focus: true

# Monitoring et export
metrics_export: true
csv_export: true
save_adaptation_history: true
verbose_adaptation: true

# Objectif de performance
performance_target:
  min_accuracy: 0.90           # Objectif minimum 90%
  target_accuracy: 0.95        # Objectif cible 95%
  stop_at_target: true         # Arr√™ter si cible atteinte

# Instructions d'utilisation
usage_instructions: |
  üéØ CONFIGURATION ADAPTATIVE POUR 90%+ ACCURACY:
  
  Cette configuration utilise l'optimisation adaptative en temps r√©el
  pour garantir une accuracy sup√©rieure √† 90%.
  
  üîß OPTIMISATIONS AUTOMATIQUES:
  - Learning rate adapt√© en temps r√©el
  - Momentum optimis√© selon convergence
  - Dropout ajust√© selon overfitting
  - Class weights √©quilibr√©s automatiquement
  
  üìä R√âSULTATS ATTENDUS:
  - Accuracy: 90-98%
  - Adaptation automatique des param√®tres
  - Convergence stable et optimale
  
  üöÄ UTILISATION:
  ./neuroplast-ann --config config/test_convergence_adaptive_90plus.yml --test-all 